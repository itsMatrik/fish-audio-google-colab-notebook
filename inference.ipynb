{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsMatrik/fish-audio-google-colab-notebook/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMNWXyfiv-IV"
      },
      "source": [
        "# Fish Speech"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **READ IT PLEASE**"
      ],
      "metadata": {
        "id": "-YganxgLBFH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is fork from original fish-speech (https://github.com/fishaudio/fish-speech). This is google colab notebook version because original repo dont have it. Fully working and ready to use. Just run commands line-by-line. You can get hugginfFace token here: https://huggingface.co/settings/tokens (first you need to create an account and subscribe on s1-mini model on huggingFace model page (its free)). If something is not working chatGPT is free"
      ],
      "metadata": {
        "id": "g3GDcunoBOsW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uSMtyf4v-IW"
      },
      "source": [
        "### For Windows User / win用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "id": "IYmQguI1v-IX",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!chcp 65001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYRyoq8Zv-IY"
      },
      "source": [
        "### For Linux User / Linux 用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "55wWJUREv-IY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc6a37f7-c697-4bf1-bc01-bd1606eaa071"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub\n",
        "import huggingface_hub\n",
        "print(\"huggingface_hub version:\", huggingface_hub.__version__)"
      ],
      "metadata": {
        "id": "ZIzkEsQLwQ8f",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9820adb5-e91d-4c37-9c0e-ca0ac4a27198"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface_hub version: 1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "hf_token = getpass(\"insert huggingFace token: \")\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "id": "yx6Ob9UmwbEY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cbdd96d-f1a9-4d5b-bc13-9fd3fa321171"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "insert huggingFace token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fishaudio/fish-speech.git"
      ],
      "metadata": {
        "id": "3Pg9HIuGwoh3",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecdffa8-86c0-444f-a555-00b448c2b3bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fish-speech'...\n",
            "remote: Enumerating objects: 6130, done.\u001b[K\n",
            "remote: Counting objects: 100% (1199/1199), done.\u001b[K\n",
            "remote: Compressing objects: 100% (293/293), done.\u001b[K\n",
            "remote: Total 6130 (delta 1044), reused 908 (delta 906), pack-reused 4931 (from 2)\u001b[K\n",
            "Receiving objects: 100% (6130/6130), 19.77 MiB | 24.28 MiB/s, done.\n",
            "Resolving deltas: 100% (3988/3988), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fish-speech"
      ],
      "metadata": {
        "id": "pDHyBWKCwyB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880e422a-7f56-42fe-cedc-468a32a21844"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fish-speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y portaudio19-dev"
      ],
      "metadata": {
        "id": "ig7tpbgpxNSX",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8329d23-2c8f-48ed-cdbc-8575dd2bf53b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  libasound2-doc jackd1 portaudio19-doc\n",
            "The following packages will be REMOVED:\n",
            "  libjack-jackd2-0\n",
            "The following NEW packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "  portaudio19-dev\n",
            "0 upgraded, 6 newly installed, 1 to remove and 41 not upgraded.\n",
            "Need to get 596 kB of archives.\n",
            "After this operation, 3,178 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack0 amd64 1:0.125.0-3build2 [93.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libasound2-dev amd64 1.2.6.1-1ubuntu1 [110 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack-dev amd64 1:0.125.0-3build2 [206 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 596 kB in 1s (436 kB/s)\n",
            "dpkg: libjack-jackd2-0:amd64: dependency problems, but removing anyway as you requested:\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            "\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Removing libjack-jackd2-0:amd64 (1.9.20~dfsg-1) ...\n",
            "Selecting previously unselected package libjack0:amd64.\n",
            "(Reading database ... 121679 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjack0_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libasound2-dev:amd64.\n",
            "Preparing to unpack .../1-libasound2-dev_1.2.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libjack-dev.\n",
            "Preparing to unpack .../2-libjack-dev_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack-dev (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "Preparing to unpack .../3-libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../4-libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../5-portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Setting up libjack-dev (1:0.125.0-3build2) ...\n",
            "Setting up libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "y84Tar1Nw2mn",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73ab909a-c5b2-4947-c2e4-b98d4c97ba04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fish-speech\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<=1.26.4 (from fish-speech==0.1.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (5.0.0)\n",
            "Collecting datasets==2.18.0 (from fish-speech==0.1.0)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning>=2.1.0 (from fish-speech==0.1.0)\n",
            "  Downloading lightning-2.6.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.3.2 (from fish-speech==0.1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: tensorboard>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (2.19.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (8.4.0)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.8.2)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: rich>=13.5.3 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: gradio>5.0.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (5.50.0)\n",
            "Requirement already satisfied: wandb>=0.15.11 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.24.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (1.76.0)\n",
            "Collecting kui>=1.6.0 (from fish-speech==0.1.0)\n",
            "  Downloading kui-1.14.0-py3-none-any.whl.metadata (982 bytes)\n",
            "Requirement already satisfied: uvicorn>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.40.0)\n",
            "Collecting loguru>=0.6.0 (from fish-speech==0.1.0)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting loralib>=0.1.2 (from fish-speech==0.1.0)\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyrootutils>=1.0.4 (from fish-speech==0.1.0)\n",
            "  Downloading pyrootutils-1.0.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting resampy>=0.4.3 (from fish-speech==0.1.0)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting einx==0.2.2 (from einx[torch]==0.2.2->fish-speech==0.1.0)\n",
            "  Downloading einx-0.2.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: zstandard>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.25.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.25.1)\n",
            "Collecting pyaudio (from fish-speech==0.1.0)\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting modelscope==1.17.1 (from fish-speech==0.1.0)\n",
            "  Downloading modelscope-1.17.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencc-python-reimplemented==0.1.7 (from fish-speech==0.1.0)\n",
            "  Downloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting silero-vad (from fish-speech==0.1.0)\n",
            "  Downloading silero_vad-6.2.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: ormsgpack in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (1.12.2)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.12.0)\n",
            "Collecting pydantic==2.9.2 (from fish-speech==0.1.0)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (6.2.6)\n",
            "Collecting descript-audio-codec (from fish-speech==0.1.0)\n",
            "  Downloading descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting descript-audiotools (from fish-speech==0.1.0)\n",
            "  Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.70.16)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (1.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.12/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope==1.17.1->fish-speech==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic==2.9.2->fish-speech==0.1.0)\n",
            "  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.11.5)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.0.22)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio>5.0.0->fish-speech==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (4.9.3)\n",
            "Collecting baize>=0.22.0 (from kui>=1.6.0->fish-speech==0.1.0)\n",
            "  Downloading baize-0.23.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.1.2)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from pyrootutils>=1.0.4->fish-speech==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.10.1)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.8.0->fish-speech==0.1.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (3.1.46)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (4.5.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (2.51.0)\n",
            "Collecting argbind>=0.3.7 (from descript-audio-codec->fish-speech==0.1.0)\n",
            "  Downloading argbind-0.3.9.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from descript-audio-codec->fish-speech==0.1.0) (2.9.0+cu126)\n",
            "Collecting pyloudnorm (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading pyloudnorm-0.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (6.5.2)\n",
            "Collecting julius (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (3.10.0)\n",
            "Collecting pystoi (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting torch-stoi (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flatten-dict (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting markdown2 (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading markdown2-2.5.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting randomname (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading randomname-0.2.1.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.14.1->fish-speech==0.1.0)\n",
            "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
            "Collecting onnxruntime>=1.16.1 (from silero-vad->fish-speech==0.1.0)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (3.11)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.12/dist-packages (from argbind>=0.3.7->descript-audio-codec->fish-speech==0.1.0) (0.17.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio>5.0.0->fish-speech==0.1.0) (0.0.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0->fish-speech==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0->fish-speech==0.1.0) (1.5.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.3->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa>=0.10.1->fish-speech==0.1.0) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0) (25.12.19)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.18.0->fish-speech==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.1->fish-speech==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa>=0.10.1->fish-speech==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.3.0)\n",
            "Collecting jedi>=0.16 (from ipython->descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (3.3.2)\n",
            "Collecting fire (from randomname->descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.10.1->fish-speech==0.1.0) (3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->descript-audiotools->fish-speech==0.1.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->descript-audiotools->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->descript-audiotools->fish-speech==0.1.0) (0.5.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->randomname->descript-audiotools->fish-speech==0.1.0) (3.3.0)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.2.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.17.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kui-1.14.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.6.1-py3-none-any.whl (853 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyrootutils-1.0.4-py3-none-any.whl (5.8 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading silero_vad-6.2.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading baize-0.23.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Downloading markdown2-2.5.4-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading pyloudnorm-0.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fish-speech, pyaudio, argbind, julius, randomname\n",
            "  Building editable for fish-speech (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fish-speech: filename=fish_speech-0.1.0-0.editable-py3-none-any.whl size=12146 sha256=fbd974a2d7171d6465666a8d54f3a843dc029710d69a6b87f1ae143964f42dcc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bc46sbwq/wheels/40/11/5d/394c2c329f7fff69f451f500aaedf1b1f21b4f749a6c4c430e\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp312-cp312-linux_x86_64.whl size=68668 sha256=44e6f1b41a53801f99a71355c13f0325ed6e765683d2cfc40d5a5efb53f0beb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/c7/33/c6a6b210cb5819ec5c219928c794a447742a7d86d21c0b92e6\n",
            "  Building wheel for argbind (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for argbind: filename=argbind-0.3.9-py2.py3-none-any.whl size=11730 sha256=af14f52a041ef561e0d7b918aec665a4d6e1da0b7ec10b7cce6a5c9ac7f69dd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/33/cb/c5e898b01c657604d61ef1462002dee37ed67b4b05b871dc45\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=9e69ebabf7379a84d5d6dbce1192f8096148d6b397cea49f14888e8a74262ded\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c1/ca/544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for randomname: filename=randomname-0.2.1-py3-none-any.whl size=89194 sha256=d43f9d9536bd56aba24aa06ab1d8ad20633cb9c2f5d1462478671a3f26c7c7ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/6e/37/1db72aaa77a57f2dcbc97fd96a47f14091130a1dde562124c0\n",
            "Successfully built fish-speech pyaudio argbind julius randomname\n",
            "Installing collected packages: pyaudio, opencc-python-reimplemented, pyrootutils, pydantic-core, pyarrow-hotfix, protobuf, numpy, markdown2, loralib, loguru, lightning-utilities, jedi, humanfriendly, fsspec, flatten-dict, fire, baize, argbind, randomname, pydantic, modelscope, hydra-core, einx, coloredlogs, resampy, pystoi, pyloudnorm, onnxruntime, kui, torchmetrics, julius, datasets, torch-stoi, silero-vad, pytorch-lightning, lightning, descript-audiotools, descript-audio-codec, fish-speech\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-pubsub 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-spanner 3.62.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.17.3 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-secret-manager 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.20.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-audit-log 0.4.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-speech 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.22.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-monitoring 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-bigtable 2.35.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-discoveryengine 0.13.12 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.3 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-iam 2.21.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.72.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed argbind-0.3.9 baize-0.23.1 coloredlogs-15.0.1 datasets-2.18.0 descript-audio-codec-1.0.0 descript-audiotools-0.7.2 einx-0.2.2 fire-0.7.1 fish-speech-0.1.0 flatten-dict-0.4.2 fsspec-2024.2.0 humanfriendly-10.0 hydra-core-1.3.2 jedi-0.19.2 julius-0.2.7 kui-1.14.0 lightning-2.6.1 lightning-utilities-0.15.2 loguru-0.7.3 loralib-0.1.2 markdown2-2.5.4 modelscope-1.17.1 numpy-1.26.4 onnxruntime-1.23.2 opencc-python-reimplemented-0.1.7 protobuf-3.19.6 pyarrow-hotfix-0.7 pyaudio-0.2.14 pydantic-2.9.2 pydantic-core-2.23.4 pyloudnorm-0.2.0 pyrootutils-1.0.4 pystoi-0.4.1 pytorch-lightning-2.6.1 randomname-0.2.1 resampy-0.4.3 silero-vad-6.2.0 torch-stoi-0.2.3 torchmetrics-1.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "61785c46b1b3489289ed6bbc2b8e42a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import sys; import torch, torchaudio; print('python', sys.version.split()[0]); print('torch', getattr(torch,'__version__',None)); print('torchaudio', getattr(torchaudio,'__version__',None))\""
      ],
      "metadata": {
        "id": "NGS_rpZg3Pqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0f8d43-6314-44a4-da23-bcde8e7aac5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python 3.12.12\n",
            "torch 2.9.0+cu126\n",
            "torchaudio 2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchaudio torch"
      ],
      "metadata": {
        "id": "s7UTwxJb3Shd",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054be3ec-aa4b-4c77-c0c1-8223b6423833"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torch==2.6.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "id": "mM7JjJYn3s6i",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "427807c3-058d-4644-9444-6a4eea25f2c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting filelock (from torch==2.6.0+cu124)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting networkx (from torch==2.6.0+cu124)\n",
            "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0+cu124)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.2.0 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting setuptools (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0+cu124)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0+cu124)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m761.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.3\n",
            "    Uninstalling filelock-3.20.3:\n",
            "      Successfully uninstalled filelock-3.20.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.18.0 requires fsspec[http]<=2024.2.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "google-cloud-functions 1.22.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-monitoring 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.6.0+cu124 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.3 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-iam 2.21.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 setuptools-70.2.0 sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 triton-3.2.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "filelock"
                ]
              },
              "id": "386375268868425e90ee8388520ccff7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchvision torchmetrics"
      ],
      "metadata": {
        "id": "1gdoeKjC490s",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7c135c-4ed7-40b8-91c4-704b42369f60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: torchmetrics 1.8.2\n",
            "Uninstalling torchmetrics-1.8.2:\n",
            "  Successfully uninstalled torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torchvision==0.21.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "id": "Lbl3Fd_t5Bhi",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9139b5d5-f89c-41a2-ec71-819614cd0419"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torchvision==0.21.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting numpy (from torchvision==0.21.0+cu124)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.6.0 (from torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0+cu124)\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting filelock (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting networkx (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting setuptools (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "Using cached https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 70.2.0\n",
            "    Uninstalling setuptools-70.2.0:\n",
            "      Successfully uninstalled setuptools-70.2.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.12.0\n",
            "    Uninstalling fsspec-2025.12.0:\n",
            "      Successfully uninstalled fsspec-2025.12.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lightning 2.6.1 requires torchmetrics<3.0,>0.7.0, which is not installed.\n",
            "pytorch-lightning 2.6.1 requires torchmetrics>0.7.0, which is not installed.\n",
            "datasets 2.18.0 requires fsspec[http]<=2024.2.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "fish-speech 0.1.0 requires numpy<=1.26.4, but you have numpy 2.3.5 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "google-cloud-functions 1.22.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-monitoring 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.3 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.21.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 numpy-2.3.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-12.0.0 setuptools-70.2.0 sympy-1.13.1 torch-2.6.0+cu124 torchvision-0.21.0+cu124 triton-3.2.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "filelock",
                  "numpy"
                ]
              },
              "id": "8be1962435b246158f8ed281da79497a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir --upgrade \"torchmetrics==1.8.2\""
      ],
      "metadata": {
        "id": "2xFhlzf155MY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5689926-0b96-4953-813e-42aaa28159f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics==1.8.2\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (2.3.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.8.2) (70.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.8.2) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.20.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (2025.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics==1.8.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics==1.8.2) (2.1.5)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchmetrics\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fish-speech 0.1.0 requires numpy<=1.26.4, but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzribO3Yv-IY"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U_TbmAcev-IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8783b3bd-97d2-4b4d-f7df-5bc49f8a5668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mA new version of huggingface_hub (1.4.0) is available! You are using version 1.3.4.\n",
            "To update, run: \u001b[1mpip install -U huggingface_hub\u001b[0m\n",
            "\u001b[0m\n",
            "Downloading (incomplete total...): 0.00B [00:00, ?B/s]\n",
            "Downloading (incomplete total...):   0% 4.38k/2.69M [00:00<07:32, 5.94kB/s]\n",
            "Downloading (incomplete total...): 100% 3.61G/3.61G [00:43<00:00, 73.8MB/s]\n",
            "Fetching 7 files: 100% 7/7 [00:43<00:00,  6.15s/it]\n",
            "Download complete: 100% 3.61G/3.61G [00:43<00:00, 73.8MB/s]                /content/fish-speech/checkpoints/openaudio-s1-mini\n",
            "Download complete: 100% 3.61G/3.61G [00:43<00:00, 83.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "# For Chinese users, you probably want to use mirror to accelerate downloading\n",
        "# !set HF_ENDPOINT=https://hf-mirror.com\n",
        "# !export HF_ENDPOINT=https://hf-mirror.com\n",
        "\n",
        "!hf download fishaudio/openaudio-s1-mini --local-dir checkpoints/openaudio-s1-mini/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOW-SVPkv-IZ"
      },
      "source": [
        "## WebUI Inference\n",
        "\n",
        "> You can use --compile to fuse CUDA kernels for faster inference (10x)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "06v5GRNvv-IZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3720203a-eacd-44a1-896a-dd4967b883ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-04 17:29:47.411724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770226187.656100    4427 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770226187.721128    4427 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770226188.199358    4427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770226188.199396    4427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770226188.199400    4427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770226188.199404    4427 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-04 17:29:48.247749: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2026-02-04 17:30:04.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mLoading Llama model...\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:04.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mLoading model from checkpoints/openaudio-s1-mini, config: DualARModelArgs(model_type='dual_ar', vocab_size=155776, n_layer=28, n_head=16, dim=1024, intermediate_size=3072, n_local_heads=8, head_dim=128, rope_base=1000000, norm_eps=1e-06, max_seq_len=8192, dropout=0.0, tie_word_embeddings=False, attention_qkv_bias=False, attention_o_bias=False, attention_qk_norm=True, codebook_size=4096, num_codebooks=10, use_gradient_checkpointing=True, initializer_range=0.03125, is_reward_model=False, scale_codebook_embeddings=True, n_fast_layer=4, fast_dim=1024, fast_n_head=16, fast_n_local_heads=8, fast_head_dim=64, fast_intermediate_size=3072, fast_attention_qkv_bias=False, fast_attention_qk_norm=False, fast_attention_o_bias=False)\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:18.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mModel weights loaded - Status: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:23.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m357\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:23.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:23.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mCompiling function...\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:23.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mLoading VQ-GAN model...\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "\u001b[32m2026-02-04 17:30:36.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.dac.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:36.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mDecoder model loaded, warming up...\u001b[0m\n",
            "\u001b[32m2026-02-04 17:30:36.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: Hello world.\u001b[0m\n",
            "  2% 17/1023 [04:28<4:25:11, 15.82s/it]\n",
            "\u001b[32m2026-02-04 17:35:06.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m482\u001b[0m - \u001b[1mCompilation time: 270.17 seconds\u001b[0m\n",
            "\u001b[32m2026-02-04 17:35:06.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 19 tokens in 270.17 seconds, 0.07 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-02-04 17:35:06.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 0.06 GB/s\u001b[0m\n",
            "\u001b[32m2026-02-04 17:35:06.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 4.92 GB\u001b[0m\n",
            "\u001b[32m2026-02-04 17:35:06.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 18])\u001b[0m\n",
            "\u001b[32m2026-02-04 17:35:10.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mWarming up done, launching the web UI...\u001b[0m\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://5153fca665a31ee355.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3043, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fish-speech/tools/run_webui.py\", line 107, in <module>\n",
            "    app.launch()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2950, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3047, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1153, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1169, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5153fca665a31ee355.gradio.live\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['GRADIO_SHARE'] = 'True'\n",
        "\n",
        "!python tools/run_webui.py \\\n",
        "  --llama-checkpoint-path checkpoints/openaudio-s1-mini \\\n",
        "  --decoder-checkpoint-path checkpoints/openaudio-s1-mini/codec.pth \\\n",
        "  --device cuda \\\n",
        "  --half \\\n",
        "  --compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhiaSCqLv-IZ"
      },
      "source": [
        "## Break-down CLI Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKwyLjT8v-Ia"
      },
      "source": [
        "### 1. Encode reference audio: / 从语音生成 prompt:\n",
        "\n",
        "You should get a `fake.npy` file.\n",
        "\n",
        "你应该能得到一个 `fake.npy` 文件."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "Q4pHId_Xv-Ia"
      },
      "outputs": [],
      "source": [
        "## Enter the path to the audio file here\n",
        "src_audio = r\"D:\\PythonProject\\vo_hutao_draw_appear.wav\"\n",
        "\n",
        "!python fish_speech/models/dac/inference.py \\\n",
        "    -i {src_audio} \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini/codec.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl8MzQ3nv-Ia"
      },
      "source": [
        "### 2. Generate semantic tokens from text: / 从文本生成语义 token:\n",
        "\n",
        "> This command will create a codes_N file in the working directory, where N is an integer starting from 0.\n",
        "\n",
        "> You may want to use `--compile` to fuse CUDA kernels for faster inference (~30 tokens/second -> ~300 tokens/second).\n",
        "\n",
        "> 该命令会在工作目录下创建 codes_N 文件, 其中 N 是从 0 开始的整数.\n",
        "\n",
        "> 您可以使用 `--compile` 来融合 cuda 内核以实现更快的推理 (~30 tokens/秒 -> ~300 tokens/秒)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "WzwPihgkv-Ia"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/text2semantic/inference.py \\\n",
        "    --text \"hello world\" \\\n",
        "    --prompt-text \"The text corresponding to reference audio\" \\\n",
        "    --prompt-tokens \"fake.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini\" \\\n",
        "    --num-samples 2\n",
        "    # --compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJebh2bAv-Ia"
      },
      "source": [
        "### 3. Generate speech from semantic tokens: / 从语义 token 生成人声:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "897M8jkNv-Ia"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/dac/inference.py \\\n",
        "    -i \"codes_0.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini/codec.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/fish-speech\n",
        "nohup python -m tools.api_server \\\n",
        "  --listen 0.0.0.0:8081 \\\n",
        "  --llama-checkpoint-path checkpoints/openaudio-s1-mini \\\n",
        "  --decoder-checkpoint-path checkpoints/openaudio-s1-mini/codec.pth \\\n",
        "  --decoder-config-name modded_dac_vq \\\n",
        "  --device cuda \\\n",
        "  --half \\\n",
        "  --compile \\\n",
        "  > server.log 2>&1 &\n"
      ],
      "metadata": {
        "id": "zqtec2a4us_T"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 50 /content/fish-speech/server.log"
      ],
      "metadata": {
        "id": "w46Bo5A9184Y",
        "outputId": "4164976b-73ab-4032-c27b-8892d8cd2f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-04 21:27:44.757 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:45 - Loaded audio with 13.64 seconds\n",
            "2026-02-04 21:27:45.144 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:52 - Encoded prompt: torch.Size([10, 294])\n",
            "2026-02-04 21:27:45.180 | INFO     | fish_speech.models.text2semantic.inference:generate_long:457 - Encoded text: Второстепенными? Я считаю их декорацией! Пока вы учите детей расставлять кнопочки на страничке, Китай и Америка на C++ и ассемблере пишут нейросети, системы управления, военные технологии! Мы отстаём, потому что занимаемся ерундой!\n",
            "\r  0%|          | 0/1023 [00:00<?, ?it/s]\r  1%|          | 6/1023 [00:00<00:19, 52.11it/s]\r  1%|          | 12/1023 [00:00<00:19, 52.04it/s]\r  2%|▏         | 18/1023 [00:00<00:19, 51.90it/s]\r  2%|▏         | 24/1023 [00:00<00:19, 51.86it/s]\r  3%|▎         | 30/1023 [00:00<00:19, 51.76it/s]\r  4%|▎         | 36/1023 [00:00<00:19, 51.89it/s]\r  4%|▍         | 42/1023 [00:00<00:18, 51.95it/s]\r  5%|▍         | 48/1023 [00:00<00:18, 51.46it/s]\r  5%|▌         | 54/1023 [00:01<00:18, 51.30it/s]\r  6%|▌         | 60/1023 [00:01<00:18, 51.45it/s]\r  6%|▋         | 66/1023 [00:01<00:18, 51.60it/s]\r  7%|▋         | 72/1023 [00:01<00:18, 51.63it/s]\r  8%|▊         | 78/1023 [00:01<00:18, 51.57it/s]\r  8%|▊         | 84/1023 [00:01<00:18, 51.40it/s]\r  9%|▉         | 90/1023 [00:01<00:18, 51.51it/s]\r  9%|▉         | 96/1023 [00:01<00:18, 51.39it/s]\r 10%|▉         | 102/1023 [00:01<00:17, 51.22it/s]\r 11%|█         | 108/1023 [00:02<00:17, 51.05it/s]\r 11%|█         | 114/1023 [00:02<00:17, 51.09it/s]\r 12%|█▏        | 120/1023 [00:02<00:17, 51.20it/s]\r 12%|█▏        | 126/1023 [00:02<00:17, 51.47it/s]\r 13%|█▎        | 132/1023 [00:02<00:17, 51.42it/s]\r 13%|█▎        | 138/1023 [00:02<00:17, 51.32it/s]\r 14%|█▍        | 144/1023 [00:02<00:17, 51.43it/s]\r 15%|█▍        | 150/1023 [00:02<00:16, 51.55it/s]\r 15%|█▌        | 156/1023 [00:03<00:16, 51.57it/s]\r 16%|█▌        | 162/1023 [00:03<00:16, 51.54it/s]\r 16%|█▋        | 168/1023 [00:03<00:16, 51.53it/s]\r 17%|█▋        | 174/1023 [00:03<00:16, 51.68it/s]\r 18%|█▊        | 180/1023 [00:03<00:16, 51.71it/s]\r 18%|█▊        | 186/1023 [00:03<00:16, 51.72it/s]\r 19%|█▉        | 192/1023 [00:03<00:16, 51.42it/s]\r 19%|█▉        | 198/1023 [00:03<00:16, 51.36it/s]\r 20%|█▉        | 204/1023 [00:03<00:15, 51.37it/s]\r 21%|██        | 210/1023 [00:04<00:15, 51.29it/s]\r 21%|██        | 216/1023 [00:04<00:15, 51.18it/s]\r 22%|██▏       | 222/1023 [00:04<00:15, 51.01it/s]\r 22%|██▏       | 228/1023 [00:04<00:15, 50.89it/s]\r 23%|██▎       | 234/1023 [00:04<00:15, 50.89it/s]\r 23%|██▎       | 240/1023 [00:04<00:15, 50.67it/s]\r 24%|██▍       | 246/1023 [00:04<00:15, 50.81it/s]\r 25%|██▍       | 252/1023 [00:04<00:15, 51.00it/s]\r 25%|██▌       | 258/1023 [00:05<00:14, 51.04it/s]\r 26%|██▌       | 264/1023 [00:05<00:14, 50.95it/s]\r 26%|██▋       | 270/1023 [00:05<00:14, 51.04it/s]\r 27%|██▋       | 276/1023 [00:05<00:14, 51.30it/s]\r 28%|██▊       | 282/1023 [00:05<00:14, 51.40it/s]\r 28%|██▊       | 288/1023 [00:05<00:14, 51.39it/s]\r 29%|██▊       | 294/1023 [00:05<00:14, 51.30it/s]\r 29%|██▉       | 300/1023 [00:05<00:14, 51.48it/s]\r 30%|██▉       | 306/1023 [00:05<00:13, 51.54it/s]\r 30%|███       | 312/1023 [00:06<00:13, 51.33it/s]\r 31%|███       | 318/1023 [00:06<00:13, 51.16it/s]\r 32%|███▏      | 324/1023 [00:06<00:13, 50.99it/s]\r 32%|███▏      | 325/1023 [00:06<00:13, 51.19it/s]\n",
            "2026-02-04 21:27:51.716 | INFO     | fish_speech.models.text2semantic.inference:generate_long:482 - Compilation time: 6.54 seconds\n",
            "2026-02-04 21:27:51.716 | INFO     | fish_speech.models.text2semantic.inference:generate_long:491 - Generated 327 tokens in 6.54 seconds, 50.03 tokens/sec\n",
            "2026-02-04 21:27:51.716 | INFO     | fish_speech.models.text2semantic.inference:generate_long:494 - Bandwidth achieved: 43.03 GB/s\n",
            "2026-02-04 21:27:51.716 | INFO     | fish_speech.models.text2semantic.inference:generate_long:497 - GPU Memory used: 6.70 GB\n",
            "2026-02-04 21:27:51.732 | INFO     | fish_speech.inference_engine.vq_manager:decode_vq_tokens:20 - VQ features: torch.Size([10, 326])\n",
            "INFO:     127.0.0.1:58362 - \"POST /v1/tts HTTP/1.1\" 200 OK\n",
            "2026-02-04 21:27:52.481 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:45 - Loaded audio with 15.49 seconds\n",
            "2026-02-04 21:27:52.921 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:52 - Encoded prompt: torch.Size([10, 334])\n",
            "2026-02-04 21:27:52.963 | INFO     | fish_speech.models.text2semantic.inference:generate_long:457 - Encoded text: Но без интерфейса, без того же HTML, даже самая мощная программа будет бесполезна для пользователя.\n",
            "\r  0%|          | 0/1023 [00:00<?, ?it/s]\r  1%|          | 6/1023 [00:00<00:19, 51.61it/s]\r  1%|          | 12/1023 [00:00<00:19, 51.55it/s]\r  2%|▏         | 18/1023 [00:00<00:19, 51.50it/s]\r  2%|▏         | 24/1023 [00:00<00:19, 51.62it/s]\r  3%|▎         | 30/1023 [00:00<00:19, 51.69it/s]\r  4%|▎         | 36/1023 [00:00<00:19, 51.70it/s]\r  4%|▍         | 42/1023 [00:00<00:18, 51.70it/s]\r  5%|▍         | 48/1023 [00:00<00:18, 51.44it/s]\r  5%|▌         | 54/1023 [00:01<00:18, 51.27it/s]\r  6%|▌         | 60/1023 [00:01<00:18, 51.45it/s]\r  6%|▋         | 66/1023 [00:01<00:18, 51.46it/s]\r  7%|▋         | 72/1023 [00:01<00:18, 51.33it/s]\r  8%|▊         | 78/1023 [00:01<00:18, 50.83it/s]\r  8%|▊         | 84/1023 [00:01<00:18, 50.66it/s]\r  9%|▉         | 90/1023 [00:01<00:18, 50.77it/s]\r  9%|▉         | 96/1023 [00:01<00:18, 50.62it/s]\r 10%|▉         | 102/1023 [00:01<00:18, 50.40it/s]\r 11%|█         | 108/1023 [00:02<00:18, 50.37it/s]\r 11%|█         | 114/1023 [00:02<00:18, 50.35it/s]\r 12%|█▏        | 120/1023 [00:02<00:17, 50.41it/s]\r 12%|█▏        | 126/1023 [00:02<00:17, 50.44it/s]\r 13%|█▎        | 132/1023 [00:02<00:17, 50.59it/s]\r 13%|█▎        | 136/1023 [00:02<00:17, 50.55it/s]\n",
            "2026-02-04 21:27:55.853 | INFO     | fish_speech.models.text2semantic.inference:generate_long:482 - Compilation time: 2.89 seconds\n",
            "2026-02-04 21:27:55.853 | INFO     | fish_speech.models.text2semantic.inference:generate_long:491 - Generated 138 tokens in 2.89 seconds, 47.76 tokens/sec\n",
            "2026-02-04 21:27:55.853 | INFO     | fish_speech.models.text2semantic.inference:generate_long:494 - Bandwidth achieved: 41.08 GB/s\n",
            "2026-02-04 21:27:55.854 | INFO     | fish_speech.models.text2semantic.inference:generate_long:497 - GPU Memory used: 6.89 GB\n",
            "2026-02-04 21:27:55.876 | INFO     | fish_speech.inference_engine.vq_manager:decode_vq_tokens:20 - VQ features: torch.Size([10, 137])\n",
            "INFO:     127.0.0.1:58248 - \"POST /v1/tts HTTP/1.1\" 200 OK\n",
            "2026-02-04 21:27:56.575 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:45 - Loaded audio with 13.64 seconds\n",
            "2026-02-04 21:27:56.978 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:52 - Encoded prompt: torch.Size([10, 294])\n",
            "2026-02-04 21:27:57.005 | INFO     | fish_speech.models.text2semantic.inference:generate_long:457 - Encoded text: Интерфейс?! Сделает дизайнер! За два дня! А движок, алгоритмы, безопасность — это годы работы серьёзных программистов на C++! Вы путаете строителя небоскрёба и маляра, который красит стены в подъезде!\n",
            "\r  0%|          | 0/1023 [00:00<?, ?it/s]\r  1%|          | 6/1023 [00:00<00:19, 51.27it/s]\r  1%|          | 12/1023 [00:00<00:19, 51.09it/s]\r  2%|▏         | 18/1023 [00:00<00:19, 51.49it/s]\r  2%|▏         | 24/1023 [00:00<00:19, 51.44it/s]\r  3%|▎         | 30/1023 [00:00<00:19, 51.42it/s]\r  4%|▎         | 36/1023 [00:00<00:19, 51.22it/s]\r  4%|▍         | 42/1023 [00:00<00:19, 51.33it/s]\r  5%|▍         | 48/1023 [00:00<00:19, 51.09it/s]\r  5%|▌         | 54/1023 [00:01<00:18, 51.21it/s]\r  6%|▌         | 60/1023 [00:01<00:18, 51.21it/s]\r  6%|▋         | 66/1023 [00:01<00:18, 51.26it/s]\r  7%|▋         | 72/1023 [00:01<00:18, 51.41it/s]\r  8%|▊         | 78/1023 [00:01<00:18, 51.61it/s]\r  8%|▊         | 84/1023 [00:01<00:18, 51.66it/s]\r  9%|▉         | 90/1023 [00:01<00:18, 51.65it/s]\r  9%|▉         | 96/1023 [00:01<00:18, 51.46it/s]\r 10%|▉         | 102/1023 [00:01<00:17, 51.44it/s]\r 11%|█         | 108/1023 [00:02<00:17, 51.50it/s]\r 11%|█         | 114/1023 [00:02<00:17, 51.38it/s]\r 12%|█▏        | 120/1023 [00:02<00:17, 51.30it/s]\r 12%|█▏        | 126/1023 [00:02<00:17, 51.25it/s]\r 13%|█▎        | 132/1023 [00:02<00:17, 51.38it/s]\r 13%|█▎        | 138/1023 [00:02<00:17, 51.44it/s]\r 14%|█▍        | 144/1023 [00:02<00:17, 51.23it/s]\r 15%|█▍        | 150/1023 [00:02<00:17, 51.01it/s]\r 15%|█▌        | 156/1023 [00:03<00:17, 50.83it/s]\r 16%|█▌        | 162/1023 [00:03<00:16, 50.84it/s]\r 16%|█▋        | 168/1023 [00:03<00:16, 50.92it/s]\r 17%|█▋        | 174/1023 [00:03<00:16, 51.18it/s]\r 18%|█▊        | 180/1023 [00:03<00:16, 51.23it/s]\r 18%|█▊        | 186/1023 [00:03<00:16, 51.36it/s]\r 19%|█▉        | 192/1023 [00:03<00:16, 51.33it/s]\r 19%|█▉        | 198/1023 [00:03<00:16, 51.44it/s]\r 20%|█▉        | 204/1023 [00:03<00:15, 51.43it/s]\r 21%|██        | 210/1023 [00:04<00:15, 51.43it/s]\r 21%|██        | 216/1023 [00:04<00:15, 51.28it/s]\r 22%|██▏       | 222/1023 [00:04<00:15, 51.20it/s]\r 22%|██▏       | 228/1023 [00:04<00:15, 51.32it/s]\r 23%|██▎       | 234/1023 [00:04<00:15, 51.42it/s]\r 23%|██▎       | 240/1023 [00:04<00:15, 51.26it/s]\r 24%|██▍       | 246/1023 [00:04<00:15, 51.01it/s]\r 25%|██▍       | 252/1023 [00:04<00:15, 50.81it/s]\r 25%|██▌       | 258/1023 [00:05<00:15, 50.79it/s]\r 26%|██▌       | 264/1023 [00:05<00:14, 50.74it/s]\r 26%|██▋       | 270/1023 [00:05<00:14, 50.98it/s]\r 27%|██▋       | 276/1023 [00:05<00:14, 50.95it/s]\r 28%|██▊       | 282/1023 [00:05<00:14, 50.90it/s]\r 28%|██▊       | 288/1023 [00:05<00:14, 50.84it/s]\r 29%|██▊       | 294/1023 [00:05<00:14, 50.89it/s]\r 29%|██▉       | 300/1023 [00:05<00:14, 50.98it/s]\r 30%|██▉       | 306/1023 [00:05<00:13, 51.30it/s]\r 30%|███       | 312/1023 [00:06<00:13, 51.22it/s]\r 31%|███       | 318/1023 [00:06<00:13, 51.26it/s]\r 32%|███▏      | 324/1023 [00:06<00:13, 51.05it/s]\r 32%|███▏      | 324/1023 [00:06<00:13, 51.05it/s]\n",
            "2026-02-04 21:28:03.538 | INFO     | fish_speech.models.text2semantic.inference:generate_long:482 - Compilation time: 6.53 seconds\n",
            "2026-02-04 21:28:03.538 | INFO     | fish_speech.models.text2semantic.inference:generate_long:491 - Generated 326 tokens in 6.53 seconds, 49.90 tokens/sec\n",
            "2026-02-04 21:28:03.538 | INFO     | fish_speech.models.text2semantic.inference:generate_long:494 - Bandwidth achieved: 42.92 GB/s\n",
            "2026-02-04 21:28:03.538 | INFO     | fish_speech.models.text2semantic.inference:generate_long:497 - GPU Memory used: 6.89 GB\n",
            "2026-02-04 21:28:03.554 | INFO     | fish_speech.inference_engine.vq_manager:decode_vq_tokens:20 - VQ features: torch.Size([10, 325])\n",
            "INFO:     127.0.0.1:58252 - \"POST /v1/tts HTTP/1.1\" 200 OK\n",
            "2026-02-04 21:28:04.297 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:45 - Loaded audio with 15.49 seconds\n",
            "2026-02-04 21:28:04.742 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:52 - Encoded prompt: torch.Size([10, 334])\n",
            "2026-02-04 21:28:04.784 | INFO     | fish_speech.models.text2semantic.inference:generate_long:457 - Encoded text: Значит, в образовании нужно делать упор на C++?\n",
            "\r  0%|          | 0/1023 [00:00<?, ?it/s]\r  1%|          | 6/1023 [00:00<00:19, 51.32it/s]\r  1%|          | 12/1023 [00:00<00:19, 51.43it/s]\r  2%|▏         | 18/1023 [00:00<00:19, 51.51it/s]\r  2%|▏         | 24/1023 [00:00<00:19, 51.41it/s]\r  3%|▎         | 30/1023 [00:00<00:19, 51.27it/s]\r  4%|▎         | 36/1023 [00:00<00:19, 51.17it/s]\r  4%|▍         | 42/1023 [00:00<00:19, 51.41it/s]\r  5%|▍         | 48/1023 [00:00<00:19, 50.91it/s]\r  5%|▌         | 54/1023 [00:01<00:19, 50.95it/s]\r  6%|▌         | 60/1023 [00:01<00:18, 51.16it/s]\r  6%|▋         | 66/1023 [00:01<00:18, 51.11it/s]\r  7%|▋         | 72/1023 [00:01<00:18, 51.32it/s]\r  8%|▊         | 78/1023 [00:01<00:18, 51.44it/s]\r  8%|▊         | 79/1023 [00:01<00:18, 50.64it/s]\n",
            "2026-02-04 21:28:06.531 | INFO     | fish_speech.models.text2semantic.inference:generate_long:482 - Compilation time: 1.75 seconds\n",
            "2026-02-04 21:28:06.531 | INFO     | fish_speech.models.text2semantic.inference:generate_long:491 - Generated 81 tokens in 1.75 seconds, 46.36 tokens/sec\n",
            "2026-02-04 21:28:06.531 | INFO     | fish_speech.models.text2semantic.inference:generate_long:494 - Bandwidth achieved: 39.88 GB/s\n",
            "2026-02-04 21:28:06.532 | INFO     | fish_speech.models.text2semantic.inference:generate_long:497 - GPU Memory used: 6.89 GB\n",
            "2026-02-04 21:28:06.551 | INFO     | fish_speech.inference_engine.vq_manager:decode_vq_tokens:20 - VQ features: torch.Size([10, 80])\n",
            "INFO:     127.0.0.1:59692 - \"POST /v1/tts HTTP/1.1\" 200 OK\n",
            "2026-02-04 21:28:07.107 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:45 - Loaded audio with 13.64 seconds\n",
            "2026-02-04 21:28:07.500 | INFO     | fish_speech.inference_engine.vq_manager:encode_reference:52 - Encoded prompt: torch.Size([10, 294])\n",
            "2026-02-04 21:28:07.540 | INFO     | fish_speech.models.text2semantic.inference:generate_long:457 - Encoded text: Конечно! Сначала математика, физика, алгоритмы, C/C++! А HTML, CSS — это как чистописание, на досуге изучите! Иначе мы воспитаем поколение оформителей, а не создателей! Страна должна создавать технологии, а не кнопочки рисовать! Всё!\n",
            "\r  0%|          | 0/1023 [00:00<?, ?it/s]\r  1%|          | 6/1023 [00:00<00:20, 50.29it/s]\r  1%|          | 12/1023 [00:00<00:20, 50.30it/s]\r  2%|▏         | 18/1023 [00:00<00:19, 50.50it/s]\r  2%|▏         | 24/1023 [00:00<00:19, 50.56it/s]\r  3%|▎         | 30/1023 [00:00<00:19, 50.37it/s]\r  4%|▎         | 36/1023 [00:00<00:19, 50.41it/s]\r  4%|▍         | 42/1023 [00:00<00:19, 50.48it/s]\r  5%|▍         | 48/1023 [00:00<00:19, 49.54it/s]\r  5%|▌         | 53/1023 [00:01<00:19, 49.20it/s]\r  6%|▌         | 58/1023 [00:01<00:19, 49.07it/s]\r  6%|▌         | 63/1023 [00:01<00:19, 49.25it/s]\r  7%|▋         | 69/1023 [00:01<00:19, 49.57it/s]\r  7%|▋         | 74/1023 [00:01<00:19, 49.33it/s]\r  8%|▊         | 79/1023 [00:01<00:19, 49.41it/s]\r  8%|▊         | 85/1023 [00:01<00:18, 49.64it/s]\r  9%|▉         | 91/1023 [00:01<00:18, 49.91it/s]\r  9%|▉         | 96/1023 [00:01<00:18, 49.93it/s]\r 10%|▉         | 102/1023 [00:02<00:18, 50.05it/s]\r 11%|█         | 108/1023 [00:02<00:18, 50.24it/s]\r 11%|█         | 114/1023 [00:02<00:18, 50.47it/s]\r 12%|█▏        | 120/1023 [00:02<00:17, 50.78it/s]\r 12%|█▏        | 126/1023 [00:02<00:17, 50.93it/s]\r 13%|█▎        | 132/1023 [00:02<00:17, 50.85it/s]\r 13%|█▎        | 138/1023 [00:02<00:17, 50.88it/s]\r 14%|█▍        | 144/1023 [00:02<00:17, 50.83it/s]\r 15%|█▍        | 150/1023 [00:02<00:17, 50.84it/s]\r 15%|█▌        | 156/1023 [00:03<00:17, 50.95it/s]\r 16%|█▌        | 162/1023 [00:03<00:16, 51.14it/s]\r 16%|█▋        | 168/1023 [00:03<00:16, 51.17it/s]\r 17%|█▋        | 174/1023 [00:03<00:16, 51.29it/s]\r 18%|█▊        | 180/1023 [00:03<00:16, 51.38it/s]\r 18%|█▊        | 186/1023 [00:03<00:16, 51.53it/s]\r 19%|█▉        | 192/1023 [00:03<00:16, 51.37it/s]\r 19%|█▉        | 198/1023 [00:03<00:16, 51.23it/s]\r 20%|█▉        | 204/1023 [00:04<00:16, 51.15it/s]\r 21%|██        | 210/1023 [00:04<00:15, 51.01it/s]\r 21%|██        | 216/1023 [00:04<00:15, 51.18it/s]\r 22%|██▏       | 222/1023 [00:04<00:15, 51.29it/s]\r 22%|██▏       | 228/1023 [00:04<00:15, 51.23it/s]\r 23%|██▎       | 234/1023 [00:04<00:15, 51.18it/s]\r 23%|██▎       | 240/1023 [00:04<00:15, 51.08it/s]\r 24%|██▍       | 246/1023 [00:04<00:15, 51.15it/s]\r 25%|██▍       | 252/1023 [00:04<00:15, 51.10it/s]\r 25%|██▌       | 258/1023 [00:05<00:15, 50.97it/s]\r 26%|██▌       | 264/1023 [00:05<00:14, 50.79it/s]\r 26%|██▋       | 270/1023 [00:05<00:14, 50.98it/s]\r 27%|██▋       | 276/1023 [00:05<00:14, 51.02it/s]\r 28%|██▊       | 282/1023 [00:05<00:14, 50.81it/s]\r 28%|██▊       | 288/1023 [00:05<00:14, 50.93it/s]\r 29%|██▊       | 294/1023 [00:05<00:14, 51.02it/s]\r 29%|██▉       | 300/1023 [00:05<00:14, 51.04it/s]\r 30%|██▉       | 306/1023 [00:06<00:14, 51.03it/s]\r 30%|███       | 312/1023 [00:06<00:13, 51.06it/s]\r 31%|███       | 318/1023 [00:06<00:13, 51.12it/s]\r 32%|███▏      | 324/1023 [00:06<00:13, 51.04it/s]\r 32%|███▏      | 330/1023 [00:06<00:13, 50.79it/s]\r 33%|███▎      | 336/1023 [00:06<00:13, 50.63it/s]\r 33%|███▎      | 342/1023 [00:06<00:13, 50.73it/s]\r 34%|███▍      | 348/1023 [00:06<00:13, 50.81it/s]\r 35%|███▍      | 354/1023 [00:06<00:13, 50.85it/s]\r 35%|███▍      | 356/1023 [00:07<00:13, 50.55it/s]\n",
            "2026-02-04 21:28:14.791 | INFO     | fish_speech.models.text2semantic.inference:generate_long:482 - Compilation time: 7.25 seconds\n",
            "2026-02-04 21:28:14.791 | INFO     | fish_speech.models.text2semantic.inference:generate_long:491 - Generated 358 tokens in 7.25 seconds, 49.37 tokens/sec\n",
            "2026-02-04 21:28:14.791 | INFO     | fish_speech.models.text2semantic.inference:generate_long:494 - Bandwidth achieved: 42.47 GB/s\n",
            "2026-02-04 21:28:14.791 | INFO     | fish_speech.models.text2semantic.inference:generate_long:497 - GPU Memory used: 6.89 GB\n",
            "2026-02-04 21:28:14.807 | INFO     | fish_speech.inference_engine.vq_manager:decode_vq_tokens:20 - VQ features: torch.Size([10, 357])\n",
            "INFO:     127.0.0.1:59702 - \"POST /v1/tts HTTP/1.1\" 200 OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ormsgpack pydub"
      ],
      "metadata": {
        "id": "k9HDmmwd2F5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, requests, ormsgpack\n",
        "from pydub import AudioSegment\n",
        "\n",
        "API_URL = \"http://127.0.0.1:8081/v1/tts\"  # <-- поменяй на 8080, если оставил 8080\n",
        "\n",
        "def to_wav_mono_44100(in_path: str, out_path: str) -> str:\n",
        "    # На всякий: mp3 -> wav (mono, 44.1k). Так стабильнее для референса.\n",
        "    a = AudioSegment.from_file(in_path)\n",
        "    a = a.set_channels(1).set_frame_rate(44100)\n",
        "    a.export(out_path, format=\"wav\")\n",
        "    return out_path\n",
        "\n",
        "def tts_one_line(text: str, ref_audio_path: str, ref_text: str, out_path: str, out_format=\"wav\"):\n",
        "    body = {\n",
        "        \"text\": text,\n",
        "        \"format\": out_format,        # \"wav\" / \"mp3\" / \"opus\" / \"pcm\"\n",
        "        \"chunk_length\": 200,\n",
        "        \"normalize\": True,\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.7,\n",
        "        \"repetition_penalty\": 1.2,\n",
        "        \"max_new_tokens\": 1024,\n",
        "        \"references\": [\n",
        "            {\n",
        "                \"audio\": open(ref_audio_path, \"rb\").read(),  # bytes -> msgpack\n",
        "                \"text\": ref_text,\n",
        "            }\n",
        "        ],\n",
        "        # \"reference_id\": None,  # если будешь использовать заранее сохранённые голоса\n",
        "    }\n",
        "\n",
        "    payload = ormsgpack.packb(body)\n",
        "    r = requests.post(\n",
        "        API_URL,\n",
        "        data=payload,\n",
        "        headers={\"Content-Type\": \"application/msgpack\"},\n",
        "        timeout=600,\n",
        "    )\n",
        "    r.raise_for_status()\n",
        "    with open(out_path, \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "\n",
        "# --- твои референсы (лучше сделать wav) ---\n",
        "voiceA_ref = to_wav_mono_44100(\"/content/fish-speech/sobaka.mp3\", \"/content/voiceA.wav\")\n",
        "voiceB_ref = to_wav_mono_44100(\"/content/fish-speech/zirik.mp3\",  \"/content/voiceB.wav\")\n",
        "\n",
        "voiceA_text = \"Это «Осторожно! Новости»! Сегодня обсуждаем: новые санкции - кто кого переиграл? Протесты в Европе - знакомый сценарий или что-то новое? Цифровизация общества - куда нас это приведёт? И конечно, громкие заявления политиков, которые нельзя пропустить.\"\n",
        "voiceB_text = \"Посмотрите, что происходит сегодня! Когда элита забывает о народе, когда чиновники думают только о себе - это путь к катастрофе. История нас учит: все империи, где власть оторвалась от народа, рухнули. Все! До единой!\"\n",
        "\n",
        "dialogue = [\n",
        "    (\"A\", \"Привет! Как дела?\"),\n",
        "    (\"B\", \"Нормально. А у тебя?\"),\n",
        "    (\"A\", \"Тоже отлично. Поехали делать диалог!\"),\n",
        "]\n",
        "\n",
        "os.makedirs(\"/content/lines\", exist_ok=True)\n",
        "\n",
        "for i, (spk, line) in enumerate(dialogue):\n",
        "    if spk == \"A\":\n",
        "        tts_one_line(line, voiceA_ref, voiceA_text, f\"/content/lines/line_{i:03d}.wav\")\n",
        "    else:\n",
        "        tts_one_line(line, voiceB_ref, voiceB_text, f\"/content/lines/line_{i:03d}.wav\")\n",
        "\n",
        "print(\"Готово: /content/lines/*.wav\")\n"
      ],
      "metadata": {
        "id": "VK53reZz2JGn",
        "outputId": "b5d2d460-b096-4943-ec30-e4d4d7ba90f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Готово: /content/lines/*.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "pause_ms = 250\n",
        "pause = AudioSegment.silent(duration=pause_ms)\n",
        "\n",
        "dialog = AudioSegment.empty()\n",
        "\n",
        "for fn in sorted(os.listdir(\"/content/lines\")):\n",
        "    if fn.endswith(\".wav\"):\n",
        "        seg = AudioSegment.from_file(f\"/content/lines/{fn}\")\n",
        "        dialog += seg + pause\n",
        "\n",
        "out_mp3 = \"/content/dialog.mp3\"\n",
        "dialog.export(out_mp3, format=\"mp3\", bitrate=\"192k\")\n",
        "out_mp3\n"
      ],
      "metadata": {
        "id": "wnwwt6Td50ao",
        "outputId": "1dd281bb-b64d-4c5c-de71-30af27cfd3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dialog.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install ffmpeg\n",
        "!pip -q install fastapi uvicorn requests ormsgpack pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW2yKkBlYLzD",
        "outputId": "d4fb3140-44da-46b0-8d3f-3fd5cd8d2ae4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/fish-speech/pipeline_server.py\n",
        "import os, io, tempfile, traceback\n",
        "import requests, ormsgpack\n",
        "from pydub import AudioSegment\n",
        "\n",
        "from fastapi import FastAPI, Header, HTTPException\n",
        "from fastapi.responses import StreamingResponse\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "\n",
        "# ✅ подключаемся к твоему fish-speech серверу правильно:\n",
        "FISH_API_URL = \"http://127.0.0.1:8081/v1/tts\"\n",
        "\n",
        "API_KEY = os.environ.get(\"PIPELINE_API_KEY\", \"change-me\")\n",
        "\n",
        "# ✅ референсы — WAV, не MP3\n",
        "VOICE_REFS = {\n",
        "    \"A\": {\n",
        "        \"audio_path\": \"/content/voiceA.wav\",\n",
        "        \"ref_text\": \"Это «Осторожно! Новости»! Сегодня обсуждаем: новые санкции...\",\n",
        "    },\n",
        "    \"B\": {\n",
        "        \"audio_path\": \"/content/voiceB.wav\",\n",
        "        \"ref_text\": \"Посмотрите, что происходит сегодня! Когда элита забывает о народе...\",\n",
        "    },\n",
        "}\n",
        "DEFAULT_SPK = \"A\"\n",
        "\n",
        "class Line(BaseModel):\n",
        "    speaker: Optional[str] = None\n",
        "    text: str\n",
        "\n",
        "class DialogueReq(BaseModel):\n",
        "    dialogue: List[Line]\n",
        "    pause_ms: int = 250\n",
        "    temperature: float = 0.7\n",
        "    top_p: float = 0.7\n",
        "    repetition_penalty: float = 1.2\n",
        "    max_new_tokens: int = 1024\n",
        "    normalize: bool = True\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "def map_speaker_to_ab(s: str) -> str:\n",
        "    # чтобы \"Ксения Собчак\" и \"Владимир Жириновский\" маппились на A/B\n",
        "    if not s:\n",
        "        return DEFAULT_SPK\n",
        "    ss = s.lower()\n",
        "    if \"собчак\" in ss or \"ксения\" in ss:\n",
        "        return \"A\"\n",
        "    if \"жиринов\" in ss or \"владимир\" in ss:\n",
        "        return \"B\"\n",
        "    return DEFAULT_SPK\n",
        "\n",
        "def _call_tts_wav(text: str, spk_ab: str, req: DialogueReq) -> bytes:\n",
        "    ref = VOICE_REFS[spk_ab]\n",
        "\n",
        "    if not os.path.exists(ref[\"audio_path\"]):\n",
        "        raise RuntimeError(f\"Reference audio not found: {ref['audio_path']}\")\n",
        "\n",
        "    body = {\n",
        "        \"text\": text,\n",
        "        \"format\": \"wav\",\n",
        "        \"chunk_length\": 200,\n",
        "        \"normalize\": req.normalize,\n",
        "        \"temperature\": req.temperature,\n",
        "        \"top_p\": req.top_p,\n",
        "        \"repetition_penalty\": req.repetition_penalty,\n",
        "        \"max_new_tokens\": req.max_new_tokens,\n",
        "        \"references\": [\n",
        "            {\"audio\": open(ref[\"audio_path\"], \"rb\").read(), \"text\": ref[\"ref_text\"]}\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    payload = ormsgpack.packb(body)\n",
        "    r = requests.post(\n",
        "        FISH_API_URL,\n",
        "        data=payload,\n",
        "        headers={\"Content-Type\": \"application/msgpack\"},\n",
        "        timeout=600,\n",
        "    )\n",
        "    r.raise_for_status()\n",
        "    return r.content\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"ok\": True}\n",
        "\n",
        "@app.post(\"/dialogue\")\n",
        "def synth_dialogue(req: DialogueReq, x_api_key: Optional[str] = Header(default=None)):\n",
        "    try:\n",
        "        if x_api_key != API_KEY:\n",
        "            raise HTTPException(status_code=401, detail=\"Bad API key\")\n",
        "\n",
        "        if not req.dialogue:\n",
        "            raise HTTPException(status_code=400, detail=\"Empty dialogue\")\n",
        "\n",
        "        tmpdir = tempfile.mkdtemp(prefix=\"dlg_\")\n",
        "        wavs = []\n",
        "\n",
        "        for i, line in enumerate(req.dialogue):\n",
        "            text = (line.text or \"\").strip()\n",
        "            if not text:\n",
        "                continue\n",
        "\n",
        "            spk_ab = map_speaker_to_ab((line.speaker or \"\").strip())\n",
        "            wav_bytes = _call_tts_wav(text, spk_ab, req)\n",
        "\n",
        "            p = os.path.join(tmpdir, f\"line_{i:03d}.wav\")\n",
        "            with open(p, \"wb\") as f:\n",
        "                f.write(wav_bytes)\n",
        "            wavs.append(p)\n",
        "\n",
        "        if not wavs:\n",
        "            raise HTTPException(status_code=400, detail=\"No non-empty lines\")\n",
        "\n",
        "        pause = AudioSegment.silent(duration=req.pause_ms)\n",
        "        out = AudioSegment.silent(duration=0)\n",
        "        for p in wavs:\n",
        "            out += AudioSegment.from_file(p) + pause\n",
        "\n",
        "        buf = io.BytesIO()\n",
        "        out.export(buf, format=\"mp3\", bitrate=\"192k\")\n",
        "        buf.seek(0)\n",
        "\n",
        "        return StreamingResponse(\n",
        "            buf,\n",
        "            media_type=\"audio/mpeg\",\n",
        "            headers={\"Content-Disposition\": 'attachment; filename=\"dialog.mp3\"'}\n",
        "        )\n",
        "\n",
        "    except HTTPException:\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        # чтобы в pipeline.log было видно конкретную причину\n",
        "        print(\"PIPELINE ERROR:\", str(e))\n",
        "        print(traceback.format_exc())\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUIy5gmxYQz4",
        "outputId": "a6377d34-122e-4457-a88f-5321cc980419"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/fish-speech/pipeline_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PIPELINE_API_KEY\"] = \"MY_SECRET_KEY_123\"  # придумай свой ключ\n",
        "\n",
        "%cd /content/fish-speech\n",
        "!nohup python -m uvicorn pipeline_server:app --app-dir /content/fish-speech --host 0.0.0.0 --port 8082 > pipeline.log 2>&1 &\n",
        "!sleep 1\n",
        "!tail -n 50 pipeline.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCBpu8pyYY9n",
        "outputId": "42aa3951-d68f-48b9-c111-f14f4629b7e6"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fish-speech\n",
            "INFO:     Started server process [19157]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8082 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f \"cloudflared tunnel\" || true\n",
        "!nohup cloudflared tunnel --url http://127.0.0.1:8082 --no-autoupdate > tunnel.log 2>&1 &\n",
        "!sleep 2\n",
        "!tail -n 50 tunnel.log\n",
        "!grep -oE \"https://[a-zA-Z0-9.-]+\\.trycloudflare\\.com\" -m 1 tunnel.log\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFWMkmPkZHHY",
        "outputId": "265498de-a944-41cc-8066-d20f2ad7d924"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "2026-02-04T21:26:05Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "2026-02-04T21:26:05Z INF Requesting new quick Tunnel on trycloudflare.com...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}