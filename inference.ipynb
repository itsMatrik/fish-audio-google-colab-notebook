{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsMatrik/fish-audio-google-colab-notebook/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMNWXyfiv-IV"
      },
      "source": [
        "# Fish Speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uSMtyf4v-IW"
      },
      "source": [
        "### For Windows User / win用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYmQguI1v-IX",
        "outputId": "b445a269-cff9-4ef9-d856-d4fb745e98c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: chcp: command not found\n"
          ]
        }
      ],
      "source": [
        "!chcp 65001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYRyoq8Zv-IY"
      },
      "source": [
        "### For Linux User / Linux 用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "55wWJUREv-IY",
        "outputId": "fbcb8413-9de7-42d5-8406-011c73628eac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub\n",
        "import huggingface_hub\n",
        "print(\"huggingface_hub version:\", huggingface_hub.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIzkEsQLwQ8f",
        "outputId": "6e254449-5fbf-4ab0-c6aa-7ca4727a54c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface_hub version: 0.36.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "hf_token = getpass(\"Вставьте ваш HF токен здесь (скрыто): \")\n",
        "login(token=hf_token) # сохранит сессию в окружении Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx6Ob9UmwbEY",
        "outputId": "caff94c6-c314-46f9-bc31-ed559cc8172e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Вставьте ваш HF токен здесь (скрыто): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fishaudio/fish-speech.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pg9HIuGwoh3",
        "outputId": "8956da26-ae88-4edc-963b-a18097c10092"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fish-speech'...\n",
            "remote: Enumerating objects: 6121, done.\u001b[K\n",
            "remote: Counting objects: 100% (999/999), done.\u001b[K\n",
            "remote: Compressing objects: 100% (273/273), done.\u001b[K\n",
            "remote: Total 6121 (delta 856), reused 726 (delta 726), pack-reused 5122 (from 2)\u001b[K\n",
            "Receiving objects: 100% (6121/6121), 19.78 MiB | 17.21 MiB/s, done.\n",
            "Resolving deltas: 100% (3981/3981), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fish-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDHyBWKCwyB3",
        "outputId": "e21386e8-ca7e-4775-e62d-ced9799c8f5e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fish-speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y portaudio19-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig7tpbgpxNSX",
        "outputId": "64ee02c2-7f1d-40e8-f26c-00769b14e11c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  libasound2-doc jackd1 portaudio19-doc\n",
            "The following packages will be REMOVED:\n",
            "  libjack-jackd2-0\n",
            "The following NEW packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "  portaudio19-dev\n",
            "0 upgraded, 6 newly installed, 1 to remove and 41 not upgraded.\n",
            "Need to get 596 kB of archives.\n",
            "After this operation, 3,178 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack0 amd64 1:0.125.0-3build2 [93.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libasound2-dev amd64 1.2.6.1-1ubuntu1 [110 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack-dev amd64 1:0.125.0-3build2 [206 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 596 kB in 2s (301 kB/s)\n",
            "dpkg: libjack-jackd2-0:amd64: dependency problems, but removing anyway as you requested:\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            "\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Removing libjack-jackd2-0:amd64 (1.9.20~dfsg-1) ...\n",
            "Selecting previously unselected package libjack0:amd64.\n",
            "(Reading database ... 121679 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjack0_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libasound2-dev:amd64.\n",
            "Preparing to unpack .../1-libasound2-dev_1.2.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libjack-dev.\n",
            "Preparing to unpack .../2-libjack-dev_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack-dev (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "Preparing to unpack .../3-libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../4-libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../5-portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Setting up libjack-dev (1:0.125.0-3build2) ...\n",
            "Setting up libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y84Tar1Nw2mn",
        "outputId": "6db4fdc7-dc69-4fb2-e8ef-6aec3f2a014e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fish-speech\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<=1.26.4 (from fish-speech==0.1.0)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (4.57.6)\n",
            "Collecting datasets==2.18.0 (from fish-speech==0.1.0)\n",
            "  Using cached datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning>=2.1.0 (from fish-speech==0.1.0)\n",
            "  Using cached lightning-2.6.1-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting hydra-core>=1.3.2 (from fish-speech==0.1.0)\n",
            "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: tensorboard>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (2.19.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (8.4.0)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.8.2)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: rich>=13.5.3 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: gradio>5.0.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (5.50.0)\n",
            "Requirement already satisfied: wandb>=0.15.11 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.24.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (1.76.0)\n",
            "Collecting kui>=1.6.0 (from fish-speech==0.1.0)\n",
            "  Using cached kui-1.14.0-py3-none-any.whl.metadata (982 bytes)\n",
            "Requirement already satisfied: uvicorn>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.40.0)\n",
            "Collecting loguru>=0.6.0 (from fish-speech==0.1.0)\n",
            "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting loralib>=0.1.2 (from fish-speech==0.1.0)\n",
            "  Using cached loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyrootutils>=1.0.4 (from fish-speech==0.1.0)\n",
            "  Using cached pyrootutils-1.0.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting resampy>=0.4.3 (from fish-speech==0.1.0)\n",
            "  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting einx==0.2.2 (from einx[torch]==0.2.2->fish-speech==0.1.0)\n",
            "  Using cached einx-0.2.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: zstandard>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.25.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.25.1)\n",
            "Collecting pyaudio (from fish-speech==0.1.0)\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting modelscope==1.17.1 (from fish-speech==0.1.0)\n",
            "  Using cached modelscope-1.17.1-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting opencc-python-reimplemented==0.1.7 (from fish-speech==0.1.0)\n",
            "  Using cached opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting silero-vad (from fish-speech==0.1.0)\n",
            "  Using cached silero_vad-6.2.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: ormsgpack in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (1.12.2)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.12.0)\n",
            "Collecting pydantic==2.9.2 (from fish-speech==0.1.0)\n",
            "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (6.2.6)\n",
            "Collecting descript-audio-codec (from fish-speech==0.1.0)\n",
            "  Using cached descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting descript-audiotools (from fish-speech==0.1.0)\n",
            "  Using cached descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.70.16)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.12/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope==1.17.1->fish-speech==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic==2.9.2->fish-speech==0.1.0)\n",
            "  Using cached pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.11.5)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.0.22)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio>5.0.0->fish-speech==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (4.9.3)\n",
            "Collecting baize>=0.22.0 (from kui>=1.6.0->fish-speech==0.1.0)\n",
            "  Using cached baize-0.23.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.1.2)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Using cached lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Using cached torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Using cached pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from pyrootutils>=1.0.4->fish-speech==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.10.1)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.8.0->fish-speech==0.1.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (3.1.46)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (4.5.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (2.51.0)\n",
            "Collecting argbind>=0.3.7 (from descript-audio-codec->fish-speech==0.1.0)\n",
            "  Using cached argbind-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from descript-audio-codec->fish-speech==0.1.0) (2.9.0+cu126)\n",
            "Collecting pyloudnorm (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached pyloudnorm-0.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (6.5.2)\n",
            "Collecting julius (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached julius-0.2.7-py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (3.10.0)\n",
            "Collecting pystoi (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting torch-stoi (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flatten-dict (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting markdown2 (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached markdown2-2.5.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting randomname (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached randomname-0.2.1-py3-none-any.whl\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.14.1->fish-speech==0.1.0)\n",
            "  Using cached protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
            "Collecting onnxruntime>=1.16.1 (from silero-vad->fish-speech==0.1.0)\n",
            "  Using cached onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (3.11)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.12/dist-packages (from argbind>=0.3.7->descript-audio-codec->fish-speech==0.1.0) (0.17.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio>5.0.0->fish-speech==0.1.0) (0.0.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0->fish-speech==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.3->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa>=0.10.1->fish-speech==0.1.0) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0) (25.12.19)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.18.0->fish-speech==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.1->fish-speech==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa>=0.10.1->fish-speech==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>5.0.0->fish-speech==0.1.0) (1.5.4)\n",
            "Collecting jedi>=0.16 (from ipython->descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (3.3.2)\n",
            "Collecting fire (from randomname->descript-audiotools->fish-speech==0.1.0)\n",
            "  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.10.1->fish-speech==0.1.0) (3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->descript-audiotools->fish-speech==0.1.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->descript-audiotools->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->descript-audiotools->fish-speech==0.1.0) (0.5.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->randomname->descript-audiotools->fish-speech==0.1.0) (3.3.0)\n",
            "Using cached datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "Using cached einx-0.2.2-py3-none-any.whl (101 kB)\n",
            "Using cached modelscope-1.17.1-py3-none-any.whl (5.7 MB)\n",
            "Using cached opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "Using cached pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Using cached kui-1.14.0-py3-none-any.whl (66 kB)\n",
            "Using cached lightning-2.6.1-py3-none-any.whl (853 kB)\n",
            "Using cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Using cached loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Using cached pyrootutils-1.0.4-py3-none-any.whl (5.8 kB)\n",
            "Using cached resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "Using cached descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\n",
            "Using cached descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\n",
            "Using cached silero_vad-6.2.0-py3-none-any.whl (6.1 MB)\n",
            "Using cached baize-0.23.1-py3-none-any.whl (52 kB)\n",
            "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "Using cached lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Using cached onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "Using cached protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
            "Using cached torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "Using cached flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Using cached markdown2-2.5.4-py3-none-any.whl (49 kB)\n",
            "Using cached pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Using cached pyloudnorm-0.2.0-py3-none-any.whl (10 kB)\n",
            "Using cached pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Using cached pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
            "Using cached torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\n",
            "Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Building wheels for collected packages: fish-speech, pyaudio\n",
            "  Building editable for fish-speech (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fish-speech: filename=fish_speech-0.1.0-0.editable-py3-none-any.whl size=12146 sha256=280fd49ddc6063e34cc8948594f379799b837e268a5c9e8405db8b1df80fad34\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6wvwsee_/wheels/40/11/5d/394c2c329f7fff69f451f500aaedf1b1f21b4f749a6c4c430e\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp312-cp312-linux_x86_64.whl size=68678 sha256=89b935c939d123aa8c5c4631a4d2e98b3542e61fe4e4429690686f5df09542ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/c7/33/c6a6b210cb5819ec5c219928c794a447742a7d86d21c0b92e6\n",
            "Successfully built fish-speech pyaudio\n",
            "Installing collected packages: pyaudio, opencc-python-reimplemented, pyrootutils, pydantic-core, pyarrow-hotfix, protobuf, numpy, markdown2, loralib, loguru, lightning-utilities, jedi, humanfriendly, fsspec, flatten-dict, fire, baize, argbind, randomname, pydantic, modelscope, hydra-core, einx, coloredlogs, resampy, pystoi, pyloudnorm, onnxruntime, kui, torchmetrics, julius, datasets, torch-stoi, silero-vad, pytorch-lightning, lightning, descript-audiotools, descript-audio-codec, fish-speech\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "googleapis-common-protos 1.72.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.21.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-monitoring 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "google-cloud-bigtable 2.35.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.3 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-secret-manager 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-resource-manager 1.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-functions 1.22.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-spanner 3.62.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.20.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-pubsub 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-speech 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.17.3 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-discoveryengine 0.13.12 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-audit-log 0.4.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed argbind-0.3.9 baize-0.23.1 coloredlogs-15.0.1 datasets-2.18.0 descript-audio-codec-1.0.0 descript-audiotools-0.7.2 einx-0.2.2 fire-0.7.1 fish-speech-0.1.0 flatten-dict-0.4.2 fsspec-2024.2.0 humanfriendly-10.0 hydra-core-1.3.2 jedi-0.19.2 julius-0.2.7 kui-1.14.0 lightning-2.6.1 lightning-utilities-0.15.2 loguru-0.7.3 loralib-0.1.2 markdown2-2.5.4 modelscope-1.17.1 numpy-1.26.4 onnxruntime-1.23.2 opencc-python-reimplemented-0.1.7 protobuf-3.19.6 pyarrow-hotfix-0.7 pyaudio-0.2.14 pydantic-2.9.2 pydantic-core-2.23.4 pyloudnorm-0.2.0 pyrootutils-1.0.4 pystoi-0.4.1 pytorch-lightning-2.6.1 randomname-0.2.1 resampy-0.4.3 silero-vad-6.2.0 torch-stoi-0.2.3 torchmetrics-1.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "c0b4ba6324404d6a84106e90d7ad5200"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzribO3Yv-IY"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_TbmAcev-IZ",
        "outputId": "f46c510d-a8cc-4804-9f9d-3d5fafafdeb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]Downloading 'README.md' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.7bc9c6ccc5e8a0f0ce233983a0f3da7d3345af34.incomplete'\n",
            "Downloading 'config.json' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.53320aac97d86ee9a5017e8b321024c879c7d9c7.incomplete'\n",
            "Downloading 'model.pth' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/YT0Y2lJH9mHYafdr2d9j82hXvzY=.9e59be7dc6714040dce3cde1f41e730c2f0daa5339785b1cd3b60041208c35e6.incomplete'\n",
            "Downloading '.gitattributes' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'special_tokens.json' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/Pdr1pnDFqf3r8xSTD-lPnaCpeRA=.954449504ac94d1a89b31aa1bc914f07f898b6bb.incomplete'\n",
            "Downloading 'codec.pth' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/Gl94AueGvIM0KbP8ia-vx4-hMMs=.74fc41c5a7151c6f350af8bd7e5d6e3accfcc7f3dfbfac23afd35af07052bb2f.incomplete'\n",
            "Downloading 'tokenizer.tiktoken' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/zENsYUfT6EG2Nj68LEJ8oOfAxB8=.9b9b0e0416d84d7c88333eb261c77e5fe2d7f7be.incomplete'\n",
            "\n",
            "README.md: 100% 2.86k/2.86k [00:00<00:00, 23.3MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/README.md\n",
            "\n",
            "config.json: 100% 844/844 [00:00<00:00, 8.16MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/config.json\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 16.9MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/.gitattributes\n",
            "Fetching 7 files:  14% 1/7 [00:00<00:03,  1.85it/s]\n",
            "special_tokens.json:   0% 0.00/126k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model.pth:   0% 0.00/1.74G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:   0% 0.00/1.87G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "special_tokens.json: 100% 126k/126k [00:00<00:00, 1.31MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/special_tokens.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.tiktoken: 100% 2.56M/2.56M [00:01<00:00, 2.50MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/tokenizer.tiktoken\n",
            "\n",
            "\n",
            "model.pth:   0% 900k/1.74G [00:02<1:07:30, 428kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:   4% 67.1M/1.87G [00:02<01:00, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  11% 201M/1.87G [00:02<00:16, 101MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  14% 269M/1.87G [00:03<00:22, 69.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:   4% 67.9M/1.74G [00:07<02:59, 9.30MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:   8% 135M/1.74G [00:08<01:26, 18.5MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.pth:  12% 202M/1.74G [00:09<00:50, 30.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  19% 353M/1.87G [00:09<00:53, 28.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  22% 420M/1.87G [00:09<00:36, 39.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  25% 463M/1.87G [00:10<00:28, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  16% 269M/1.74G [00:10<00:35, 40.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  19% 336M/1.74G [00:10<00:22, 61.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  23% 403M/1.74G [00:10<00:16, 80.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  27% 470M/1.74G [00:10<00:11, 107MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  28% 530M/1.87G [00:11<00:27, 48.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  31% 537M/1.74G [00:11<00:10, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  35% 604M/1.74G [00:11<00:08, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  32% 597M/1.87G [00:12<00:22, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  38% 663M/1.74G [00:12<00:08, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  42% 730M/1.74G [00:12<00:06, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  46% 797M/1.74G [00:14<00:13, 68.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  54% 931M/1.74G [00:14<00:06, 115MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  36% 664M/1.87G [00:15<00:30, 39.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  58% 998M/1.74G [00:18<00:15, 47.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  39% 731M/1.87G [00:18<00:40, 28.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  43% 798M/1.87G [00:19<00:27, 38.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  46% 865M/1.87G [00:19<00:19, 52.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  61% 1.07G/1.74G [00:19<00:12, 53.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  65% 1.13G/1.74G [00:19<00:08, 68.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  69% 1.20G/1.74G [00:20<00:05, 91.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  50% 932M/1.87G [00:20<00:16, 55.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  73% 1.27G/1.74G [00:20<00:04, 94.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  53% 1.00G/1.87G [00:20<00:12, 71.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  77% 1.33G/1.74G [00:22<00:06, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  57% 1.07G/1.87G [00:22<00:15, 51.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  81% 1.40G/1.74G [00:23<00:04, 76.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  61% 1.13G/1.87G [00:23<00:11, 66.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  64% 1.20G/1.87G [00:23<00:07, 89.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  68% 1.27G/1.87G [00:23<00:05, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  85% 1.47G/1.74G [00:23<00:03, 77.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  71% 1.33G/1.87G [00:24<00:04, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  75% 1.40G/1.87G [00:24<00:03, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  79% 1.47G/1.87G [00:24<00:02, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  88% 1.53G/1.74G [00:25<00:02, 72.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  92% 1.60G/1.74G [00:25<00:01, 85.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  82% 1.54G/1.87G [00:25<00:02, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  96% 1.67G/1.74G [00:26<00:00, 94.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  86% 1.60G/1.87G [00:26<00:02, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth: 100% 1.74G/1.74G [00:26<00:00, 65.6MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/model.pth\n",
            "\n",
            "\n",
            "\n",
            "codec.pth:  89% 1.67G/1.87G [00:26<00:01, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  93% 1.74G/1.87G [00:26<00:00, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  96% 1.80G/1.87G [00:27<00:00, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth: 100% 1.87G/1.87G [00:27<00:00, 68.2MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/codec.pth\n",
            "Fetching 7 files: 100% 7/7 [00:27<00:00,  4.00s/it]\n",
            "/content/fish-speech/checkpoints/openaudio-s1-mini\n"
          ]
        }
      ],
      "source": [
        "# For Chinese users, you probably want to use mirror to accelerate downloading\n",
        "# !set HF_ENDPOINT=https://hf-mirror.com\n",
        "# !export HF_ENDPOINT=https://hf-mirror.com\n",
        "\n",
        "!hf download fishaudio/openaudio-s1-mini --local-dir checkpoints/openaudio-s1-mini/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import sys; import torch, torchaudio; print('python', sys.version.split()[0]); print('torch', getattr(torch,'__version__',None)); print('torchaudio', getattr(torchaudio,'__version__',None))\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGS_rpZg3Pqa",
        "outputId": "779de0bd-43dd-49b1-8c41-2eaa4bd1f9dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python 3.12.12\n",
            "torch 2.9.0+cu126\n",
            "torchaudio 2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchaudio torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7UTwxJb3Shd",
        "outputId": "49f68a39-7736-4f1e-b05d-fa64644fb882"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi || echo 'no nvidia'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwDLn0PI3Ued",
        "outputId": "b15e2e8f-d68b-4351-86b8-062a425c1a3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 31 21:02:44 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torch==2.6.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mM7JjJYn3s6i",
        "outputId": "e10e6bf8-7ae1-418f-bac1-bef3aa91c9ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting filelock (from torch==2.6.0+cu124)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting networkx (from torch==2.6.0+cu124)\n",
            "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0+cu124)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.2.0 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting setuptools (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0+cu124)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0+cu124)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m798.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.3\n",
            "    Uninstalling filelock-3.20.3:\n",
            "      Successfully uninstalled filelock-3.20.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.18.0 requires fsspec[http]<=2024.2.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.6.0+cu124 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-spanner 3.62.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.20.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-speech 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 setuptools-70.2.0 sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 triton-3.2.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "filelock"
                ]
              },
              "id": "9ac7938230bf46b69245239b25500ee8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchvision torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gdoeKjC490s",
        "outputId": "e3f5a64e-00f4-4a5c-a268-14104cb1c3bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchmetrics as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torchvision==0.21.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lbl3Fd_t5Bhi",
        "outputId": "cb11ecd1-6b05-4e3b-94c4-0f0cf775a81e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torchvision==0.21.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting numpy (from torchvision==0.21.0+cu124)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.6.0 (from torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0+cu124)\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting filelock (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting networkx (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting setuptools (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "Using cached https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 70.2.0\n",
            "    Uninstalling setuptools-70.2.0:\n",
            "      Successfully uninstalled setuptools-70.2.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.12.0\n",
            "    Uninstalling fsspec-2025.12.0:\n",
            "      Successfully uninstalled fsspec-2025.12.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytorch-lightning 2.6.1 requires torchmetrics>0.7.0, which is not installed.\n",
            "lightning 2.6.1 requires torchmetrics<3.0,>0.7.0, which is not installed.\n",
            "fish-speech 0.1.0 requires numpy<=1.26.4, but you have numpy 2.3.5 which is incompatible.\n",
            "datasets 2.18.0 requires fsspec[http]<=2024.2.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-spanner 3.62.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.20.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-speech 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 numpy-2.3.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-12.0.0 setuptools-70.2.0 sympy-1.13.1 torch-2.6.0+cu124 torchvision-0.21.0+cu124 triton-3.2.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "filelock",
                  "numpy"
                ]
              },
              "id": "46479ed17c0f46e0adb9ec587a975a11"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir --upgrade \"torchmetrics==1.8.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xFhlzf155MY",
        "outputId": "c4f23aa9-271f-4b11-e266-9a5098093ab0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics==1.8.2\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (2.3.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.8.2) (70.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.8.2) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.20.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (2025.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics==1.8.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics==1.8.2) (2.1.5)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m147.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOW-SVPkv-IZ"
      },
      "source": [
        "## WebUI Inference\n",
        "\n",
        "> You can use --compile to fuse CUDA kernels for faster inference (10x)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06v5GRNvv-IZ",
        "outputId": "510d6a96-b6d7-43b7-aa82-cd8ee40297b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-31 21:27:04.002290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769894824.034834   15171 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769894824.044850   15171 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769894824.068803   15171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769894824.068843   15171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769894824.068851   15171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769894824.068858   15171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-31 21:27:04.075440: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2026-01-31 21:27:13.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mLoading Llama model...\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:13.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mLoading model from checkpoints/openaudio-s1-mini, config: DualARModelArgs(model_type='dual_ar', vocab_size=155776, n_layer=28, n_head=16, dim=1024, intermediate_size=3072, n_local_heads=8, head_dim=128, rope_base=1000000, norm_eps=1e-06, max_seq_len=8192, dropout=0.0, tie_word_embeddings=False, attention_qkv_bias=False, attention_o_bias=False, attention_qk_norm=True, codebook_size=4096, num_codebooks=10, use_gradient_checkpointing=True, initializer_range=0.03125, is_reward_model=False, scale_codebook_embeddings=True, n_fast_layer=4, fast_dim=1024, fast_n_head=16, fast_n_local_heads=8, fast_head_dim=64, fast_intermediate_size=3072, fast_attention_qkv_bias=False, fast_attention_qk_norm=False, fast_attention_o_bias=False)\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:27.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mModel weights loaded - Status: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:29.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m357\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:29.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:29.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mLoading VQ-GAN model...\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "\u001b[32m2026-01-31 21:27:37.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.dac.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:37.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mDecoder model loaded, warming up...\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:37.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: Hello world.\u001b[0m\n",
            "  2% 17/1023 [00:02<02:50,  5.90it/s]\n",
            "\u001b[32m2026-01-31 21:27:41.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 19 tokens in 3.78 seconds, 5.02 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:41.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 4.32 GB/s\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:41.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 4.90 GB\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:41.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 18])\u001b[0m\n",
            "\u001b[32m2026-01-31 21:27:42.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mWarming up done, launching the web UI...\u001b[0m\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://c59c92540a30a5164a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "\u001b[32m2026-01-31 21:31:17.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mLoaded audio with 75.84 seconds\u001b[0m\n",
            "\u001b[32m2026-01-31 21:31:21.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mEncoded prompt: torch.Size([10, 1634])\u001b[0m\n",
            "\u001b[32m2026-01-31 21:31:21.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: Доллар, доллар, доллар, это грязная зеленая бумажка! Ни души нет, ни музыки!\u001b[0m\n",
            "  2% 107/6115 [00:16<15:12,  6.58it/s]\n",
            "\u001b[32m2026-01-31 21:31:41.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 109 tokens in 19.35 seconds, 5.63 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-01-31 21:31:41.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 4.85 GB/s\u001b[0m\n",
            "\u001b[32m2026-01-31 21:31:41.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 11.37 GB\u001b[0m\n",
            "\u001b[32m2026-01-31 21:31:41.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 108])\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "\u001b[32m2026-01-31 21:33:39.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.reference_loader\u001b[0m:\u001b[36mload_by_hash\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mUse same references\u001b[0m\n",
            "\u001b[32m2026-01-31 21:33:39.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: Это что, Америка, бля? Вы что де́лаете, бля? Мо́ника, бля! Како́й, на́хуй, президе́нт? Кака́я война́? Како́й Бли́жний Восто́к, бля?\u001b[0m\n",
            "  3% 158/6077 [00:24<15:02,  6.56it/s]\n",
            "\u001b[32m2026-01-31 21:34:07.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 160 tokens in 27.35 seconds, 5.85 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-01-31 21:34:07.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 5.03 GB/s\u001b[0m\n",
            "\u001b[32m2026-01-31 21:34:07.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 11.37 GB\u001b[0m\n",
            "\u001b[32m2026-01-31 21:34:07.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 159])\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['GRADIO_SHARE'] = 'True'\n",
        "!python tools/run_webui.py \\\n",
        "  --llama-checkpoint-path checkpoints/openaudio-s1-mini \\\n",
        "  --decoder-checkpoint-path checkpoints/openaudio-s1-mini/codec.pth \\\n",
        "  #--compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhiaSCqLv-IZ"
      },
      "source": [
        "## Break-down CLI Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKwyLjT8v-Ia"
      },
      "source": [
        "### 1. Encode reference audio: / 从语音生成 prompt:\n",
        "\n",
        "You should get a `fake.npy` file.\n",
        "\n",
        "你应该能得到一个 `fake.npy` 文件."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "Q4pHId_Xv-Ia"
      },
      "outputs": [],
      "source": [
        "## Enter the path to the audio file here\n",
        "src_audio = r\"D:\\PythonProject\\vo_hutao_draw_appear.wav\"\n",
        "\n",
        "!python fish_speech/models/dac/inference.py \\\n",
        "    -i {src_audio} \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini/codec.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl8MzQ3nv-Ia"
      },
      "source": [
        "### 2. Generate semantic tokens from text: / 从文本生成语义 token:\n",
        "\n",
        "> This command will create a codes_N file in the working directory, where N is an integer starting from 0.\n",
        "\n",
        "> You may want to use `--compile` to fuse CUDA kernels for faster inference (~30 tokens/second -> ~300 tokens/second).\n",
        "\n",
        "> 该命令会在工作目录下创建 codes_N 文件, 其中 N 是从 0 开始的整数.\n",
        "\n",
        "> 您可以使用 `--compile` 来融合 cuda 内核以实现更快的推理 (~30 tokens/秒 -> ~300 tokens/秒)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "WzwPihgkv-Ia"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/text2semantic/inference.py \\\n",
        "    --text \"hello world\" \\\n",
        "    --prompt-text \"The text corresponding to reference audio\" \\\n",
        "    --prompt-tokens \"fake.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini\" \\\n",
        "    --num-samples 2\n",
        "    # --compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJebh2bAv-Ia"
      },
      "source": [
        "### 3. Generate speech from semantic tokens: / 从语义 token 生成人声:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "897M8jkNv-Ia"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/dac/inference.py \\\n",
        "    -i \"codes_0.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini/codec.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}