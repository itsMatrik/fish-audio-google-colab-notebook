{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsMatrik/fish-audio-google-colab-notebook/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMNWXyfiv-IV"
      },
      "source": [
        "# Fish Speech"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **READ IT PLEASE**"
      ],
      "metadata": {
        "id": "-YganxgLBFH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is fork from original fish-speech (https://github.com/fishaudio/fish-speech). This is google colab notebook version because original repo dont have it. Fully working and ready to use. Just run commands line-by-line. You can get hugginfFace token here: https://huggingface.co/settings/tokens (first you need to create an account and subscribe on s1-mini model on huggingFace model page (its free))"
      ],
      "metadata": {
        "id": "g3GDcunoBOsW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uSMtyf4v-IW"
      },
      "source": [
        "### For Windows User / win用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYmQguI1v-IX",
        "outputId": "440c96f6-f361-483a-8beb-610a38060a5b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: chcp: command not found\n"
          ]
        }
      ],
      "source": [
        "!chcp 65001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYRyoq8Zv-IY"
      },
      "source": [
        "### For Linux User / Linux 用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "55wWJUREv-IY",
        "outputId": "bb73126b-89b2-49c1-bb9f-517dd3ccf894",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub\n",
        "import huggingface_hub\n",
        "print(\"huggingface_hub version:\", huggingface_hub.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIzkEsQLwQ8f",
        "outputId": "502c7de2-93a5-4fa7-9c01-3a4de3273c3d",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface_hub version: 0.36.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from huggingface_hub import login\n",
        "hf_token = getpass(\"insert huggingFace token: \")\n",
        "login(token=hf_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx6Ob9UmwbEY",
        "outputId": "cb58e20d-cf01-40b1-ab4d-af1f70f82e4a",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Вставьте ваш HF токен здесь (скрыто): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fishaudio/fish-speech.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pg9HIuGwoh3",
        "outputId": "9360f15c-cbb4-4b49-b171-ba90521d7583",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fish-speech'...\n",
            "remote: Enumerating objects: 6121, done.\u001b[K\n",
            "remote: Counting objects: 100% (1190/1190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (286/286), done.\u001b[K\n",
            "remote: Total 6121 (delta 1040), reused 904 (delta 904), pack-reused 4931 (from 2)\u001b[K\n",
            "Receiving objects: 100% (6121/6121), 19.77 MiB | 16.08 MiB/s, done.\n",
            "Resolving deltas: 100% (3984/3984), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fish-speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDHyBWKCwyB3",
        "outputId": "8b7ec374-5070-4455-d6c6-fed476e265e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fish-speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y portaudio19-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig7tpbgpxNSX",
        "outputId": "b19f051c-c202-4626-c1cd-fd0ffa6ef77f",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  libasound2-doc jackd1 portaudio19-doc\n",
            "The following packages will be REMOVED:\n",
            "  libjack-jackd2-0\n",
            "The following NEW packages will be installed:\n",
            "  libasound2-dev libjack-dev libjack0 libportaudio2 libportaudiocpp0\n",
            "  portaudio19-dev\n",
            "0 upgraded, 6 newly installed, 1 to remove and 41 not upgraded.\n",
            "Need to get 596 kB of archives.\n",
            "After this operation, 3,178 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack0 amd64 1:0.125.0-3build2 [93.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libasound2-dev amd64 1.2.6.1-1ubuntu1 [110 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjack-dev amd64 1:0.125.0-3build2 [206 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 596 kB in 1s (407 kB/s)\n",
            "dpkg: libjack-jackd2-0:amd64: dependency problems, but removing anyway as you requested:\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            " libavdevice58:amd64 depends on libjack-jackd2-0 (>= 1.9.10+20150825) | libjack-0.125; however:\n",
            "  Package libjack-jackd2-0:amd64 is to be removed.\n",
            "  Package libjack-0.125 is not installed.\n",
            "  Package libjack-jackd2-0:amd64 which provides libjack-0.125 is to be removed.\n",
            "\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Removing libjack-jackd2-0:amd64 (1.9.20~dfsg-1) ...\n",
            "Selecting previously unselected package libjack0:amd64.\n",
            "(Reading database ... 121679 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjack0_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libasound2-dev:amd64.\n",
            "Preparing to unpack .../1-libasound2-dev_1.2.6.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libjack-dev.\n",
            "Preparing to unpack .../2-libjack-dev_1%3a0.125.0-3build2_amd64.deb ...\n",
            "Unpacking libjack-dev (1:0.125.0-3build2) ...\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "Preparing to unpack .../3-libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../4-libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../5-portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libjack0:amd64 (1:0.125.0-3build2) ...\n",
            "Setting up libjack-dev (1:0.125.0-3build2) ...\n",
            "Setting up libasound2-dev:amd64 (1.2.6.1-1ubuntu1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y84Tar1Nw2mn",
        "outputId": "25c9d301-f4d2-402c-ad6c-864e5b77769c",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fish-speech\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy<=1.26.4 (from fish-speech==0.1.0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (4.57.6)\n",
            "Collecting datasets==2.18.0 (from fish-speech==0.1.0)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning>=2.1.0 (from fish-speech==0.1.0)\n",
            "  Downloading lightning-2.6.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.3.2 (from fish-speech==0.1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: tensorboard>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (2.19.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (8.4.0)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.8.2)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: rich>=13.5.3 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: gradio>5.0.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (5.50.0)\n",
            "Requirement already satisfied: wandb>=0.15.11 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.24.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (1.76.0)\n",
            "Collecting kui>=1.6.0 (from fish-speech==0.1.0)\n",
            "  Downloading kui-1.14.0-py3-none-any.whl.metadata (982 bytes)\n",
            "Requirement already satisfied: uvicorn>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.40.0)\n",
            "Collecting loguru>=0.6.0 (from fish-speech==0.1.0)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting loralib>=0.1.2 (from fish-speech==0.1.0)\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyrootutils>=1.0.4 (from fish-speech==0.1.0)\n",
            "  Downloading pyrootutils-1.0.4-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting resampy>=0.4.3 (from fish-speech==0.1.0)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting einx==0.2.2 (from einx[torch]==0.2.2->fish-speech==0.1.0)\n",
            "  Downloading einx-0.2.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: zstandard>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.25.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.25.1)\n",
            "Collecting pyaudio (from fish-speech==0.1.0)\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting modelscope==1.17.1 (from fish-speech==0.1.0)\n",
            "  Downloading modelscope-1.17.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencc-python-reimplemented==0.1.7 (from fish-speech==0.1.0)\n",
            "  Downloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting silero-vad (from fish-speech==0.1.0)\n",
            "  Downloading silero_vad-6.2.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: ormsgpack in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (1.12.2)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (0.12.0)\n",
            "Collecting pydantic==2.9.2 (from fish-speech==0.1.0)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from fish-speech==0.1.0) (6.2.6)\n",
            "Collecting descript-audio-codec (from fish-speech==0.1.0)\n",
            "  Downloading descript_audio_codec-1.0.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting descript-audiotools (from fish-speech==0.1.0)\n",
            "  Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.70.16)\n",
            "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->fish-speech==0.1.0)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.12/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope==1.17.1->fish-speech==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (0.7.0)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic==2.9.2->fish-speech==0.1.0)\n",
            "  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.11.5)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (11.3.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.0.22)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.21.1)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio>5.0.0->fish-speech==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (4.9.3)\n",
            "Collecting baize>=0.22.0 (from kui>=1.6.0->fish-speech==0.1.0)\n",
            "  Downloading baize-0.23.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.1.2)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting torchmetrics<3.0,>0.7.0 (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pytorch-lightning (from lightning>=2.1.0->fish-speech==0.1.0)\n",
            "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from pyrootutils>=1.0.4->fish-speech==0.1.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.10.1)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.8.0->fish-speech==0.1.0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (3.1.46)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (4.5.1)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (2.51.0)\n",
            "Collecting argbind>=0.3.7 (from descript-audio-codec->fish-speech==0.1.0)\n",
            "  Downloading argbind-0.3.9.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from descript-audio-codec->fish-speech==0.1.0) (2.9.0+cu126)\n",
            "Collecting pyloudnorm (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading pyloudnorm-0.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (6.5.2)\n",
            "Collecting julius (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading julius-0.2.7.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from descript-audiotools->fish-speech==0.1.0) (3.10.0)\n",
            "Collecting pystoi (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting torch-stoi (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading torch_stoi-0.2.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting flatten-dict (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading flatten_dict-0.4.2-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting markdown2 (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading markdown2-2.5.4-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting randomname (from descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading randomname-0.2.1.tar.gz (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard>=2.14.1->fish-speech==0.1.0)\n",
            "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
            "Collecting onnxruntime>=1.16.1 (from silero-vad->fish-speech==0.1.0)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (3.11)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.12/dist-packages (from argbind>=0.3.7->descript-audio-codec->fish-speech==0.1.0) (0.17.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio>5.0.0->fish-speech==0.1.0) (0.0.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.22.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets==2.18.0->fish-speech==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.3->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa>=0.10.1->fish-speech==0.1.0) (0.43.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0) (25.12.19)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.18.0->fish-speech==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.10.1->fish-speech==0.1.0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa>=0.10.1->fish-speech==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>5.0.0->fish-speech==0.1.0) (1.5.4)\n",
            "Collecting jedi>=0.16 (from ipython->descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->descript-audiotools->fish-speech==0.1.0) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->descript-audiotools->fish-speech==0.1.0) (3.3.2)\n",
            "Collecting fire (from randomname->descript-audiotools->fish-speech==0.1.0)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.10.1->fish-speech==0.1.0) (3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->descript-audiotools->fish-speech==0.1.0) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->descript-audiotools->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->descript-audiotools->fish-speech==0.1.0) (0.5.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.1->silero-vad->fish-speech==0.1.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->randomname->descript-audiotools->fish-speech==0.1.0) (3.3.0)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einx-0.2.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.17.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m140.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kui-1.14.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.6.1-py3-none-any.whl (853 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyrootutils-1.0.4-py3-none-any.whl (5.8 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading descript_audio_codec-1.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading descript_audiotools-0.7.2-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading silero_vad-6.2.0-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading baize-0.23.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatten_dict-0.4.2-py2.py3-none-any.whl (9.7 kB)\n",
            "Downloading markdown2-2.5.4-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading pyloudnorm-0.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_stoi-0.2.3-py3-none-any.whl (8.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fish-speech, pyaudio, argbind, julius, randomname\n",
            "  Building editable for fish-speech (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fish-speech: filename=fish_speech-0.1.0-0.editable-py3-none-any.whl size=12146 sha256=8d9f4fbc541076ac4739448a108240347bd458f22d7daf4e6d3338b553ba6676\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-62s1cf8d/wheels/40/11/5d/394c2c329f7fff69f451f500aaedf1b1f21b4f749a6c4c430e\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp312-cp312-linux_x86_64.whl size=68676 sha256=fd001d381093b931f1f4a42d8a952321deaf851e73c38c00fee4846cfd0949ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/c7/33/c6a6b210cb5819ec5c219928c794a447742a7d86d21c0b92e6\n",
            "  Building wheel for argbind (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for argbind: filename=argbind-0.3.9-py2.py3-none-any.whl size=11730 sha256=6efc8f8f28baa82b4cbe74e973ae466bcaaa5ba67dc6d56ab750243324c723a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/33/cb/c5e898b01c657604d61ef1462002dee37ed67b4b05b871dc45\n",
            "  Building wheel for julius (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21870 sha256=9c9564762317046313583bf4e07844b2f3a263c78322cf72793af8372623a16c\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c1/ca/544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
            "  Building wheel for randomname (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for randomname: filename=randomname-0.2.1-py3-none-any.whl size=89194 sha256=8fabefddb42abdaf1edddab938d999a51e55c9f23cbd186962e8f4e1af3d9474\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/6e/37/1db72aaa77a57f2dcbc97fd96a47f14091130a1dde562124c0\n",
            "Successfully built fish-speech pyaudio argbind julius randomname\n",
            "Installing collected packages: pyaudio, opencc-python-reimplemented, pyrootutils, pydantic-core, pyarrow-hotfix, protobuf, numpy, markdown2, loralib, loguru, lightning-utilities, jedi, humanfriendly, fsspec, flatten-dict, fire, baize, argbind, randomname, pydantic, modelscope, hydra-core, einx, coloredlogs, resampy, pystoi, pyloudnorm, onnxruntime, kui, torchmetrics, julius, datasets, torch-stoi, silero-vad, pytorch-lightning, lightning, descript-audiotools, descript-audio-codec, fish-speech\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "googleapis-common-protos 1.72.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.21.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-monitoring 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "google-cloud-bigtable 2.35.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.3 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-secret-manager 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-resource-manager 1.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-functions 1.22.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-spanner 3.62.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.20.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "opencv-python 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-pubsub 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "opencv-python-headless 4.13.0.90 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-speech 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.17.3 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-discoveryengine 0.13.12 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-audit-log 0.4.0 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed argbind-0.3.9 baize-0.23.1 coloredlogs-15.0.1 datasets-2.18.0 descript-audio-codec-1.0.0 descript-audiotools-0.7.2 einx-0.2.2 fire-0.7.1 fish-speech-0.1.0 flatten-dict-0.4.2 fsspec-2024.2.0 humanfriendly-10.0 hydra-core-1.3.2 jedi-0.19.2 julius-0.2.7 kui-1.14.0 lightning-2.6.1 lightning-utilities-0.15.2 loguru-0.7.3 loralib-0.1.2 markdown2-2.5.4 modelscope-1.17.1 numpy-1.26.4 onnxruntime-1.23.2 opencc-python-reimplemented-0.1.7 protobuf-3.19.6 pyarrow-hotfix-0.7 pyaudio-0.2.14 pydantic-2.9.2 pydantic-core-2.23.4 pyloudnorm-0.2.0 pyrootutils-1.0.4 pystoi-0.4.1 pytorch-lightning-2.6.1 randomname-0.2.1 resampy-0.4.3 silero-vad-6.2.0 torch-stoi-0.2.3 torchmetrics-1.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "a54112d50f02487791284420fe59377c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import sys; import torch, torchaudio; print('python', sys.version.split()[0]); print('torch', getattr(torch,'__version__',None)); print('torchaudio', getattr(torchaudio,'__version__',None))\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGS_rpZg3Pqa",
        "outputId": "e481c6de-a7f6-4553-8bd9-c91beb3fd01f",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python 3.12.12\n",
            "torch 2.9.0+cu126\n",
            "torchaudio 2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchaudio torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7UTwxJb3Shd",
        "outputId": "15053368-54fa-4207-869d-a9cd0ff5d609",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchaudio 2.9.0+cu126\n",
            "Uninstalling torchaudio-2.9.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Found existing installation: torch 2.9.0+cu126\n",
            "Uninstalling torch-2.9.0+cu126:\n",
            "  Successfully uninstalled torch-2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torch==2.6.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mM7JjJYn3s6i",
        "outputId": "5783690a-5574-4968-916d-09f1e52395b0",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting filelock (from torch==2.6.0+cu124)\n",
            "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting networkx (from torch==2.6.0+cu124)\n",
            "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0+cu124)\n",
            "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.2.0 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting setuptools (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0+cu124)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0+cu124)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.3\n",
            "    Uninstalling filelock-3.20.3:\n",
            "      Successfully uninstalled filelock-3.20.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.18.0 requires fsspec[http]<=2024.2.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.6.0+cu124 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-spanner 3.62.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.20.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-speech 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 setuptools-70.2.0 sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 triton-3.2.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "filelock"
                ]
              },
              "id": "276b7e5ec6a748cc84641bf9595ed54a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torchvision torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gdoeKjC490s",
        "outputId": "0959dc8b-e0f3-4737-f24a-c32945ade164",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.24.0+cu126\n",
            "Uninstalling torchvision-0.24.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.24.0+cu126\n",
            "Found existing installation: torchmetrics 1.8.2\n",
            "Uninstalling torchmetrics-1.8.2:\n",
            "  Successfully uninstalled torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torchvision==0.21.0+cu124 --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lbl3Fd_t5Bhi",
        "outputId": "2e5a7441-8ad6-4c2b-e2c0-a04bcafb208c",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torchvision==0.21.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting numpy (from torchvision==0.21.0+cu124)\n",
            "  Downloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.6.0 (from torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0+cu124)\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting filelock (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting networkx (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jinja2 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting setuptools (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0->torchvision==0.21.0+cu124)\n",
            "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.3.5-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached https://download.pytorch.org/whl/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
            "Using cached https://download.pytorch.org/whl/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
            "Using cached https://download.pytorch.org/whl/setuptools-70.2.0-py3-none-any.whl (930 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, setuptools, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 70.2.0\n",
            "    Uninstalling setuptools-70.2.0:\n",
            "      Successfully uninstalled setuptools-70.2.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.6.1\n",
            "    Uninstalling networkx-3.6.1:\n",
            "      Successfully uninstalled networkx-3.6.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.12.0\n",
            "    Uninstalling fsspec-2025.12.0:\n",
            "      Successfully uninstalled fsspec-2025.12.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.20.0\n",
            "    Uninstalling filelock-3.20.0:\n",
            "      Successfully uninstalled filelock-3.20.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytorch-lightning 2.6.1 requires torchmetrics>0.7.0, which is not installed.\n",
            "lightning 2.6.1 requires torchmetrics<3.0,>0.7.0, which is not installed.\n",
            "fish-speech 0.1.0 requires numpy<=1.26.4, but you have numpy 2.3.5 which is incompatible.\n",
            "datasets 2.18.0 requires fsspec[http]<=2024.2.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "mcp 1.26.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.5 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-logging 3.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "ydf 0.14.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.135.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-spanner 3.62.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.20.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "google-cloud-appengine-logging 1.8.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.34.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.9 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-trace 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-speech 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.23.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-dataproc 5.24.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.36.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.6.1 numpy-2.3.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-12.0.0 setuptools-70.2.0 sympy-1.13.1 torch-2.6.0+cu124 torchvision-0.21.0+cu124 triton-3.2.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "filelock",
                  "numpy"
                ]
              },
              "id": "ff6c549933a34fb3a4269a895b3f704d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir --upgrade \"torchmetrics==1.8.2\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xFhlzf155MY",
        "outputId": "c091a770-3fec-4cb6-ca5a-145950a46b8e",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics==1.8.2\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (2.3.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics==1.8.2) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.8.2) (70.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.8.2) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.20.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (2025.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics==1.8.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics==1.8.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics==1.8.2) (2.1.5)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m206.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzribO3Yv-IY"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_TbmAcev-IZ",
        "outputId": "31a852ab-9fd7-4e1e-f129-704111bf626d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]Downloading 'special_tokens.json' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/Pdr1pnDFqf3r8xSTD-lPnaCpeRA=.954449504ac94d1a89b31aa1bc914f07f898b6bb.incomplete'\n",
            "Downloading 'tokenizer.tiktoken' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/zENsYUfT6EG2Nj68LEJ8oOfAxB8=.9b9b0e0416d84d7c88333eb261c77e5fe2d7f7be.incomplete'\n",
            "Downloading 'README.md' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.7bc9c6ccc5e8a0f0ce233983a0f3da7d3345af34.incomplete'\n",
            "Downloading '.gitattributes' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'config.json' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.53320aac97d86ee9a5017e8b321024c879c7d9c7.incomplete'\n",
            "Downloading 'codec.pth' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/Gl94AueGvIM0KbP8ia-vx4-hMMs=.74fc41c5a7151c6f350af8bd7e5d6e3accfcc7f3dfbfac23afd35af07052bb2f.incomplete'\n",
            "Downloading 'model.pth' to 'checkpoints/openaudio-s1-mini/.cache/huggingface/download/YT0Y2lJH9mHYafdr2d9j82hXvzY=.9e59be7dc6714040dce3cde1f41e730c2f0daa5339785b1cd3b60041208c35e6.incomplete'\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 9.82MB/s]\n",
            "\n",
            "README.md: 100% 2.86k/2.86k [00:00<00:00, 23.9MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/.gitattributes\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/README.md\n",
            "Fetching 7 files:  14% 1/7 [00:00<00:02,  2.02it/s]\n",
            "special_tokens.json:   0% 0.00/126k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer.tiktoken:   0% 0.00/2.56M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "config.json: 100% 844/844 [00:00<00:00, 9.39MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/config.json\n",
            "special_tokens.json: 100% 126k/126k [00:00<00:00, 1.39MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/special_tokens.json\n",
            "\n",
            "model.pth:   0% 0.00/1.74G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:   0% 0.00/1.87G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.tiktoken: 100% 2.56M/2.56M [00:00<00:00, 8.26MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/tokenizer.tiktoken\n",
            "\n",
            "model.pth:   0% 900k/1.74G [00:01<1:03:52, 453kB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:   4% 67.1M/1.87G [00:02<00:57, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:   7% 135M/1.87G [00:02<00:24, 71.1MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  11% 202M/1.87G [00:02<00:15, 108MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  15% 285M/1.87G [00:06<00:44, 35.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:   4% 68.0M/1.74G [00:08<03:03, 9.06MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  18% 329M/1.87G [00:08<00:50, 30.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:   8% 135M/1.74G [00:09<01:33, 17.2MB/s] \u001b[A\n",
            "model.pth:  12% 202M/1.74G [00:09<00:52, 29.1MB/s]\u001b[A\n",
            "model.pth:  16% 269M/1.74G [00:09<00:31, 46.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  21% 396M/1.87G [00:10<00:43, 34.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  19% 336M/1.74G [00:10<00:23, 60.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  25% 463M/1.87G [00:10<00:29, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  28% 530M/1.87G [00:11<00:22, 60.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  23% 403M/1.74G [00:11<00:20, 65.6MB/s]\u001b[A\n",
            "model.pth:  27% 470M/1.74G [00:11<00:14, 90.1MB/s]\u001b[A\n",
            "model.pth:  31% 537M/1.74G [00:11<00:10, 113MB/s] \u001b[A\n",
            "model.pth:  35% 605M/1.74G [00:12<00:08, 139MB/s]\u001b[A\n",
            "model.pth:  39% 672M/1.74G [00:12<00:06, 169MB/s]\u001b[A\n",
            "model.pth:  43% 739M/1.74G [00:12<00:05, 184MB/s]\u001b[A\n",
            "model.pth:  46% 806M/1.74G [00:12<00:05, 183MB/s]\u001b[A\n",
            "model.pth:  50% 873M/1.74G [00:13<00:03, 219MB/s]\u001b[A\n",
            "model.pth:  54% 940M/1.74G [00:13<00:03, 208MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  32% 597M/1.87G [00:13<00:28, 44.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  58% 1.01G/1.74G [00:13<00:04, 182MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  36% 664M/1.87G [00:14<00:22, 53.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  62% 1.07G/1.74G [00:16<00:10, 65.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  39% 731M/1.87G [00:16<00:26, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  66% 1.14G/1.74G [00:16<00:07, 82.6MB/s]\u001b[A\n",
            "model.pth:  70% 1.21G/1.74G [00:16<00:04, 109MB/s] \u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  43% 798M/1.87G [00:17<00:20, 53.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  73% 1.27G/1.74G [00:17<00:04, 114MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  46% 865M/1.87G [00:17<00:16, 62.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  77% 1.34G/1.74G [00:18<00:03, 114MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  50% 933M/1.87G [00:18<00:12, 75.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  81% 1.41G/1.74G [00:18<00:02, 136MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  53% 1.00G/1.87G [00:18<00:09, 89.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  85% 1.48G/1.74G [00:18<00:01, 135MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  57% 1.07G/1.87G [00:19<00:08, 99.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  89% 1.54G/1.74G [00:19<00:01, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  61% 1.13G/1.87G [00:19<00:06, 107MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  64% 1.20G/1.87G [00:19<00:05, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  68% 1.27G/1.87G [00:20<00:03, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  71% 1.33G/1.87G [00:20<00:03, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  75% 1.40G/1.87G [00:20<00:02, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  78% 1.47G/1.87G [00:20<00:02, 198MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  82% 1.54G/1.87G [00:21<00:01, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  92% 1.60G/1.74G [00:21<00:01, 66.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  86% 1.60G/1.87G [00:21<00:01, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  89% 1.67G/1.87G [00:22<00:01, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth:  96% 1.67G/1.74G [00:22<00:00, 71.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  93% 1.74G/1.87G [00:22<00:00, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "codec.pth:  96% 1.80G/1.87G [00:22<00:00, 198MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model.pth: 100% 1.74G/1.74G [00:23<00:00, 75.3MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/model.pth\n",
            "\n",
            "\n",
            "\n",
            "codec.pth: 100% 1.87G/1.87G [00:23<00:00, 80.3MB/s]\n",
            "Download complete. Moving file to checkpoints/openaudio-s1-mini/codec.pth\n",
            "Fetching 7 files: 100% 7/7 [00:23<00:00,  3.41s/it]\n",
            "/content/fish-speech/checkpoints/openaudio-s1-mini\n"
          ]
        }
      ],
      "source": [
        "# For Chinese users, you probably want to use mirror to accelerate downloading\n",
        "# !set HF_ENDPOINT=https://hf-mirror.com\n",
        "# !export HF_ENDPOINT=https://hf-mirror.com\n",
        "\n",
        "!hf download fishaudio/openaudio-s1-mini --local-dir checkpoints/openaudio-s1-mini/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOW-SVPkv-IZ"
      },
      "source": [
        "## WebUI Inference\n",
        "\n",
        "> You can use --compile to fuse CUDA kernels for faster inference (10x)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06v5GRNvv-IZ",
        "outputId": "f0a03131-01ba-4306-83f2-083232637cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-01 20:44:45.533234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769978685.819884    4932 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769978685.894814    4932 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769978686.460908    4932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769978686.460955    4932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769978686.460960    4932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769978686.460964    4932 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-01 20:44:46.516289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2026-02-01 20:45:01.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m59\u001b[0m - \u001b[1mLoading Llama model...\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:01.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mLoading model from checkpoints/openaudio-s1-mini, config: DualARModelArgs(model_type='dual_ar', vocab_size=155776, n_layer=28, n_head=16, dim=1024, intermediate_size=3072, n_local_heads=8, head_dim=128, rope_base=1000000, norm_eps=1e-06, max_seq_len=8192, dropout=0.0, tie_word_embeddings=False, attention_qkv_bias=False, attention_o_bias=False, attention_qk_norm=True, codebook_size=4096, num_codebooks=10, use_gradient_checkpointing=True, initializer_range=0.03125, is_reward_model=False, scale_codebook_embeddings=True, n_fast_layer=4, fast_dim=1024, fast_n_head=16, fast_n_local_heads=8, fast_head_dim=64, fast_intermediate_size=3072, fast_attention_qkv_bias=False, fast_attention_qk_norm=False, fast_attention_o_bias=False)\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:15.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mModel weights loaded - Status: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:21.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m357\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:21.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m362\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:21.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36minit_model\u001b[0m:\u001b[36m375\u001b[0m - \u001b[1mCompiling function...\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:21.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mLoading VQ-GAN model...\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "\u001b[32m2026-02-01 20:45:36.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.dac.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:36.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mDecoder model loaded, warming up...\u001b[0m\n",
            "\u001b[32m2026-02-01 20:45:36.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: Hello world.\u001b[0m\n",
            "  3% 28/1023 [04:31<2:40:37,  9.69s/it]\n",
            "\u001b[32m2026-02-01 20:50:08.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m482\u001b[0m - \u001b[1mCompilation time: 272.37 seconds\u001b[0m\n",
            "\u001b[32m2026-02-01 20:50:08.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 30 tokens in 272.37 seconds, 0.11 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-02-01 20:50:08.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 0.09 GB/s\u001b[0m\n",
            "\u001b[32m2026-02-01 20:50:08.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 4.92 GB\u001b[0m\n",
            "\u001b[32m2026-02-01 20:50:08.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 29])\u001b[0m\n",
            "\u001b[32m2026-02-01 20:50:11.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mWarming up done, launching the web UI...\u001b[0m\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://081323cb08d5632ba3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "\u001b[32m2026-02-01 20:55:13.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mLoaded audio with 14.65 seconds\u001b[0m\n",
            "\u001b[32m2026-02-01 20:55:14.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mEncoded prompt: torch.Size([10, 316])\u001b[0m\n",
            "\u001b[32m2026-02-01 20:55:14.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: Не надо шутить с войной. Здесь другие ребята. Это не Германия, это не Афганистан. Джордж, твоих солдат здесь порвут на части. 250 тысяч отборных солдат Ирака. Они все разнесут. Они всю пустыню пройдут за один час Они взорвут все твои эсминцы, всех твоих журналистов, дипломатов. Джордж, ты ковбой. Ты остановись, бля, ты кончай, ты патроны спрячь подальше на склад и забудь про своего папу.\u001b[0m\n",
            "  8% 614/7621 [00:12<02:26, 47.96it/s]\n",
            "\u001b[32m2026-02-01 20:55:27.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m482\u001b[0m - \u001b[1mCompilation time: 13.04 seconds\u001b[0m\n",
            "\u001b[32m2026-02-01 20:55:27.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 616 tokens in 13.04 seconds, 47.24 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-02-01 20:55:27.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 40.63 GB/s\u001b[0m\n",
            "\u001b[32m2026-02-01 20:55:27.138\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 6.01 GB\u001b[0m\n",
            "\u001b[32m2026-02-01 20:55:27.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 615])\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "\u001b[32m2026-02-01 20:59:18.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.reference_loader\u001b[0m:\u001b[36mload_by_hash\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mUse same references\u001b[0m\n",
            "\u001b[32m2026-02-01 20:59:18.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: И ты никогда здесь не сможешь добиться победы. Все арабы мира, все мусульмане мира, вся восточная Европа, Москва, - все против тебя. Москва, Москва не хочет этой войны, и тебе наш президент это ясно, по-русски, сказал: \"Не сметь стрелять по Багдаду\". Лучше вместе ебанем по Тбилиси. Баку, другие города. Мы найдем цели на этой земле. Столько земли, бля . Хочешь, Австралию нахуй опустим, блять, на дно океана. Показать тебе нашу ракету, блять? Хочешь, блять? У нас тут оружия, блять.\n",
            "Ночью наши ученые чуть-чуть изменят гравитационное поле Земли, и твоя страна будет под водой. 24 часа, блять, и вся твоя страна будет под водой Атлантического Тихого океана. Ты с кем шутишь, блять? Ты подумай, блять! Ты понял, чем кончил Бонапарт, чем кончил Гитлер, все остальные? Ты совершишь историческую ошибку! Твой папа тебе благодарен не будет. Забудь его, твоего папу. Твои генералы тебе говорят - не начинай войну. Еще не поздно! Еще только 21 июня 41-го года!\"\u001b[0m\n",
            " 19% 1425/7397 [00:30<02:08, 46.55it/s]\n",
            "\u001b[32m2026-02-01 20:59:49.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m482\u001b[0m - \u001b[1mCompilation time: 30.98 seconds\u001b[0m\n",
            "\u001b[32m2026-02-01 20:59:49.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 1427 tokens in 30.98 seconds, 46.06 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-02-01 20:59:49.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 39.62 GB/s\u001b[0m\n",
            "\u001b[32m2026-02-01 20:59:49.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 8.75 GB\u001b[0m\n",
            "\u001b[32m2026-02-01 20:59:49.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 1426])\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "\u001b[32m2026-02-01 21:00:01.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.reference_loader\u001b[0m:\u001b[36mload_by_hash\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mUse same references\u001b[0m\n",
            "\u001b[32m2026-02-01 21:00:01.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: И ты никогда здесь не сможешь добиться победы. Все арабы мира, все мусульмане мира, вся восточная Европа, Москва, - все против тебя. Москва, Москва не хочет этой войны, и тебе наш президент это ясно, по-русски, сказал: \"Не сметь стрелять по Багдаду\". Лучше вместе ебанем по Тбилиси. Баку, другие города. Мы найдем цели на этой земле. Столько земли, бля . Хочешь, Австралию нахуй опустим, блять, на дно океана. Показать тебе нашу ракету, блять? Хочешь, блять? У нас тут оружия, блять.\n",
            "Ночью наши ученые чуть-чуть изменят гравитационное поле Земли, и твоя страна будет под водой. 24 часа, блять, и вся твоя страна будет под водой Атлантического Тихого океана. Ты с кем шутишь, блять? Ты подумай, блять! Ты понял, чем кончил Бонапарт, чем кончил Гитлер, все остальные? Ты совершишь историческую ошибку! Твой папа тебе благодарен не будет. Забудь его, твоего папу. Твои генералы тебе говорят - не начинай войну. Еще не поздно! Еще только 21 июня 41-го года!\"\u001b[0m\n",
            " 20% 1485/7397 [00:31<02:06, 46.75it/s]\n",
            "\u001b[32m2026-02-01 21:00:33.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m482\u001b[0m - \u001b[1mCompilation time: 32.19 seconds\u001b[0m\n",
            "\u001b[32m2026-02-01 21:00:33.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 1487 tokens in 32.19 seconds, 46.19 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-02-01 21:00:33.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 39.74 GB/s\u001b[0m\n",
            "\u001b[32m2026-02-01 21:00:33.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 13.76 GB\u001b[0m\n",
            "\u001b[32m2026-02-01 21:00:33.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 1486])\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "\u001b[32m2026-02-01 21:01:33.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.reference_loader\u001b[0m:\u001b[36mload_by_hash\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mUse same references\u001b[0m\n",
            "\u001b[32m2026-02-01 21:01:33.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEncoded text: Она гибнет. Твоя молодежь бежит из твоей страны. Там никто не хочет жить в Америке, никто! Эта барахолка, бля! Доллар, доллар, доллар, Эта грязная зеленая бумажка! Ни души, музыки нету, бля, нет писателей у тебя. Весь мир слушает Чайковского, Достоевского, бля! Фестивали, спорт только в России… И здесь, в Ираке. Здесь любят президента, а тебя презирают, презирают. Твой предшественник, бля, Клинтон, бля, ему ширинку оттянули прямо в рабочем кабинете. Это совсем уже охуеть, блять! Чтобы какая-то проститутка, блять, в кабинете главы государства ему отсасывала. \n",
            "\u001b[0m\n",
            " 11% 845/7552 [00:18<02:23, 46.64it/s]\n",
            "\u001b[32m2026-02-01 21:01:51.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m482\u001b[0m - \u001b[1mCompilation time: 18.47 seconds\u001b[0m\n",
            "\u001b[32m2026-02-01 21:01:51.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m491\u001b[0m - \u001b[1mGenerated 847 tokens in 18.48 seconds, 45.85 tokens/sec\u001b[0m\n",
            "\u001b[32m2026-02-01 21:01:51.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m494\u001b[0m - \u001b[1mBandwidth achieved: 39.43 GB/s\u001b[0m\n",
            "\u001b[32m2026-02-01 21:01:51.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m497\u001b[0m - \u001b[1mGPU Memory used: 14.12 GB\u001b[0m\n",
            "\u001b[32m2026-02-01 21:01:51.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([10, 846])\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3043, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fish-speech/tools/run_webui.py\", line 107, in <module>\n",
            "    app.launch()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 2950, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\", line 3047, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1153, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.12/threading.py\", line 1169, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://081323cb08d5632ba3.gradio.live\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['GRADIO_SHARE'] = 'True'\n",
        "\n",
        "!python tools/run_webui.py \\\n",
        "  --llama-checkpoint-path checkpoints/openaudio-s1-mini \\\n",
        "  --decoder-checkpoint-path checkpoints/openaudio-s1-mini/codec.pth \\\n",
        "  --device cuda \\\n",
        "  --half \\\n",
        "  --compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhiaSCqLv-IZ"
      },
      "source": [
        "## Break-down CLI Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKwyLjT8v-Ia"
      },
      "source": [
        "### 1. Encode reference audio: / 从语音生成 prompt:\n",
        "\n",
        "You should get a `fake.npy` file.\n",
        "\n",
        "你应该能得到一个 `fake.npy` 文件."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "Q4pHId_Xv-Ia"
      },
      "outputs": [],
      "source": [
        "## Enter the path to the audio file here\n",
        "src_audio = r\"D:\\PythonProject\\vo_hutao_draw_appear.wav\"\n",
        "\n",
        "!python fish_speech/models/dac/inference.py \\\n",
        "    -i {src_audio} \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini/codec.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl8MzQ3nv-Ia"
      },
      "source": [
        "### 2. Generate semantic tokens from text: / 从文本生成语义 token:\n",
        "\n",
        "> This command will create a codes_N file in the working directory, where N is an integer starting from 0.\n",
        "\n",
        "> You may want to use `--compile` to fuse CUDA kernels for faster inference (~30 tokens/second -> ~300 tokens/second).\n",
        "\n",
        "> 该命令会在工作目录下创建 codes_N 文件, 其中 N 是从 0 开始的整数.\n",
        "\n",
        "> 您可以使用 `--compile` 来融合 cuda 内核以实现更快的推理 (~30 tokens/秒 -> ~300 tokens/秒)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "WzwPihgkv-Ia"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/text2semantic/inference.py \\\n",
        "    --text \"hello world\" \\\n",
        "    --prompt-text \"The text corresponding to reference audio\" \\\n",
        "    --prompt-tokens \"fake.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini\" \\\n",
        "    --num-samples 2\n",
        "    # --compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJebh2bAv-Ia"
      },
      "source": [
        "### 3. Generate speech from semantic tokens: / 从语义 token 生成人声:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "897M8jkNv-Ia"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/dac/inference.py \\\n",
        "    -i \"codes_0.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/openaudio-s1-mini/codec.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}